#!/usr/bin/env python3
"""
SSE Testing CLI Tool

ä¸€ä¸ªç®€å•çš„å‘½ä»¤è¡Œå·¥å…·ï¼Œç”¨äºæµ‹è¯•å‰ç«¯ SSE åŠŸèƒ½ã€‚
ç›´æ¥é€šè¿‡ Redis å‘é€ SSE äº‹ä»¶ç»™æŒ‡å®šç”¨æˆ·ï¼Œæ— éœ€è®¤è¯æµç¨‹ã€‚

Usage:
    # å‘é€æµ‹è¯•æ¶ˆæ¯ç»™ç”¨æˆ· 1
    python sse_test_cli.py send --user-id 1 --event-type "test.message" --data '{"message": "Hello World"}'

    # è¿è¡Œæ¼”ç¤ºæ¨¡å¼ï¼Œå‘é€å¤šä¸ªæµ‹è¯•äº‹ä»¶
    python sse_test_cli.py demo --user-id 1

    # æ£€æŸ¥ Redis ä¸­çš„ç”¨æˆ·äº‹ä»¶å†å²
    python sse_test_cli.py history --user-id 1 --limit 5

    # æ¸…ç†æ‰€æœ‰ SSE è¿æ¥å’Œäº‹ä»¶æµ (è¯•è¿è¡Œ)
    python sse_test_cli.py cleanup --dry-run

    # æ¸…ç†æ‰€æœ‰ SSE è¿æ¥å’Œäº‹ä»¶æµ (å®é™…æ‰§è¡Œ)
    python sse_test_cli.py cleanup --force
"""

import argparse
import asyncio
import json
import logging
import sys
from datetime import UTC, datetime
from pathlib import Path
from typing import Any

# Add the backend source to Python path
backend_src_path = Path(__file__).parent.parent / "src"
sys.path.insert(0, str(backend_src_path))

from src.db.redis import RedisService, redis_service
from src.schemas.sse import EventScope, create_sse_message
from src.services.sse import RedisSSEService

# Configure logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)


class SSETestClient:
    """ç®€åŒ–çš„ SSE æµ‹è¯•å®¢æˆ·ç«¯ï¼Œç›´æ¥é€šè¿‡ Redis å‘é€äº‹ä»¶ã€‚"""

    def __init__(self):
        self.redis_service: RedisService | None = None
        self.sse_service: RedisSSEService | None = None

    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£ã€‚"""
        # åˆå§‹åŒ– Redis æœåŠ¡
        self.redis_service = redis_service
        await self.redis_service.connect()

        # åˆå§‹åŒ– SSE æœåŠ¡
        self.sse_service = RedisSSEService(self.redis_service)
        await self.sse_service.init_pubsub_client()

        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£ã€‚"""
        if self.sse_service:
            await self.sse_service.close()
        if self.redis_service:
            await self.redis_service.disconnect()

    async def send_event(
        self,
        user_id: str,
        event_type: str,
        data: dict[str, Any],
        scope: EventScope = EventScope.USER,
    ) -> str:
        """å‘é€ SSE äº‹ä»¶ç»™æŒ‡å®šç”¨æˆ·ã€‚"""
        if not self.sse_service:
            raise RuntimeError("SSE service not initialized")

        # åˆ›å»º SSE æ¶ˆæ¯
        sse_message = create_sse_message(event_type=event_type, data=data, scope=scope)

        # å‘å¸ƒäº‹ä»¶
        stream_id = await self.sse_service.publish_event(user_id, sse_message)

        logger.info(f"âœ… å·²å‘é€äº‹ä»¶ {event_type} ç»™ç”¨æˆ· {user_id}, stream_id: {stream_id}")
        return stream_id

    async def get_user_events_history(self, user_id: str, limit: int = 10) -> list:
        """è·å–ç”¨æˆ·çš„ SSE äº‹ä»¶å†å²ã€‚"""
        if not self.sse_service:
            raise RuntimeError("SSE service not initialized")

        events = await self.sse_service.get_recent_events(user_id, since_id="-")
        return events[-limit:] if len(events) > limit else events

    async def cleanup_all_connections(self, dry_run: bool = False) -> dict[str, int]:
        """æ¸…ç†æ‰€æœ‰ SSE è¿æ¥å’Œäº‹ä»¶æµã€‚"""
        if not self.redis_service:
            raise RuntimeError("Redis service not initialized")

        cleanup_stats = {
            "event_streams_deleted": 0,
            "connection_counters_deleted": 0,
            "other_keys_deleted": 0,
            "total_deleted": 0,
        }

        # æ‰«æå¹¶åˆ é™¤æ‰€æœ‰ SSE ç›¸å…³çš„é”®
        patterns_to_clean = [
            "events:user:*",  # SSE äº‹ä»¶æµ
            "user:*:sse_conns",  # ç”¨æˆ·è¿æ¥è®¡æ•°å™¨
        ]

        async with self.redis_service.acquire() as redis_client:
            # å¤„ç†æ¨¡å¼åŒ¹é…çš„é”®
            for pattern in patterns_to_clean:
                logger.info(f"ğŸ” æ‰«æåŒ¹é…æ¨¡å¼: {pattern}")

                cursor = 0
                keys_to_delete = []

                while True:
                    cursor, keys = await redis_client.scan(cursor=cursor, match=pattern, count=100)
                    keys_to_delete.extend(keys)

                    if cursor == 0:
                        break

                if keys_to_delete:
                    logger.info(f"ğŸ“‹ æ‰¾åˆ° {len(keys_to_delete)} ä¸ªé”®åŒ¹é…æ¨¡å¼ {pattern}")

                    if not dry_run:
                        # æ‰¹é‡åˆ é™¤é”®
                        deleted_count = await redis_client.delete(*keys_to_delete)
                        logger.info(f"ğŸ—‘ï¸  åˆ é™¤äº† {deleted_count} ä¸ªé”®")

                        # ç»Ÿè®¡ä¸åŒç±»å‹çš„é”®
                        for key in keys_to_delete:
                            key_str = key.decode() if isinstance(key, bytes) else key
                            if key_str.startswith("events:user:"):
                                cleanup_stats["event_streams_deleted"] += 1
                            elif key_str.startswith("user:") and key_str.endswith(":sse_conns"):
                                cleanup_stats["connection_counters_deleted"] += 1
                            else:
                                cleanup_stats["other_keys_deleted"] += 1

                        cleanup_stats["total_deleted"] += deleted_count
                    else:
                        logger.info(f"ğŸƒ è¯•è¿è¡Œæ¨¡å¼ - å°†åˆ é™¤ {len(keys_to_delete)} ä¸ªé”®")
                        # åœ¨ dry run æ¨¡å¼ä¸‹ä»ç„¶ç»Ÿè®¡
                        for key in keys_to_delete:
                            key_str = key.decode() if isinstance(key, bytes) else key
                            if key_str.startswith("events:user:"):
                                cleanup_stats["event_streams_deleted"] += 1
                            elif key_str.startswith("user:") and key_str.endswith(":sse_conns"):
                                cleanup_stats["connection_counters_deleted"] += 1
                            else:
                                cleanup_stats["other_keys_deleted"] += 1

                        cleanup_stats["total_deleted"] += len(keys_to_delete)
                else:
                    logger.info(f"âœ… æ²¡æœ‰æ‰¾åˆ°åŒ¹é…æ¨¡å¼ {pattern} çš„é”®")

            # å¤„ç†å…¨å±€è¿æ¥è®¡æ•°å™¨ (ç‰¹å®šé”®å)
            global_counter_key = "global:sse_connections_count"
            logger.info(f"ğŸ” æ£€æŸ¥å…¨å±€è¿æ¥è®¡æ•°å™¨: {global_counter_key}")

            global_exists = await redis_client.exists(global_counter_key)
            if global_exists:
                logger.info("ğŸ“‹ æ‰¾åˆ°å…¨å±€è¿æ¥è®¡æ•°å™¨")

                if not dry_run:
                    deleted_count = await redis_client.delete(global_counter_key)
                    logger.info("ğŸ—‘ï¸  åˆ é™¤äº†å…¨å±€è¿æ¥è®¡æ•°å™¨")
                    cleanup_stats["other_keys_deleted"] += deleted_count
                    cleanup_stats["total_deleted"] += deleted_count
                else:
                    logger.info("ğŸƒ è¯•è¿è¡Œæ¨¡å¼ - å°†åˆ é™¤å…¨å±€è¿æ¥è®¡æ•°å™¨")
                    cleanup_stats["other_keys_deleted"] += 1
                    cleanup_stats["total_deleted"] += 1
            else:
                logger.info("âœ… å…¨å±€è¿æ¥è®¡æ•°å™¨ä¸å­˜åœ¨")

        return cleanup_stats


async def cmd_send(args):
    """å‘é€æµ‹è¯• SSE äº‹ä»¶ã€‚"""
    try:
        data = json.loads(args.data)
    except json.JSONDecodeError as e:
        logger.error(f"âŒ æ— æ•ˆçš„ JSON æ•°æ®: {e}")
        return

    scope = EventScope(args.scope) if args.scope else EventScope.USER

    async with SSETestClient() as client:
        stream_id = await client.send_event(user_id=args.user_id, event_type=args.event_type, data=data, scope=scope)

        print("âœ… äº‹ä»¶å‘é€æˆåŠŸ!")
        print(f"   ç”¨æˆ· ID: {args.user_id}")
        print(f"   äº‹ä»¶ç±»å‹: {args.event_type}")
        print(f"   æµ ID: {stream_id}")
        print(f"   æ•°æ®: {json.dumps(data, indent=2, ensure_ascii=False)}")


async def cmd_demo(args):
    """è¿è¡Œæ¼”ç¤ºæ¨¡å¼ï¼Œå‘é€å¤šä¸ªæµ‹è¯•äº‹ä»¶ã€‚"""
    test_events = [
        {
            "event_type": "system.notification-sent",
            "data": {
                "level": "info",
                "title": "æ¬¢è¿ä½¿ç”¨!",
                "message": "SSE æµ‹è¯•å·¥å…·è¿è¡Œæ­£å¸¸",
                "action_required": False,
            },
        },
        {
            "event_type": "task.progress-updated",
            "data": {
                "task_id": "demo-task-123",
                "progress": 25,
                "message": "æ­£åœ¨å¤„ç†ä½ çš„è¯·æ±‚...",
                "estimated_remaining": 15,
            },
        },
        {
            "event_type": "task.progress-updated",
            "data": {
                "task_id": "demo-task-123",
                "progress": 75,
                "message": "å³å°†å®Œæˆ...",
                "estimated_remaining": 5,
            },
        },
        {
            "event_type": "task.status-changed",
            "data": {
                "task_id": "demo-task-123",
                "old_status": "running",
                "new_status": "completed",
                "timestamp": datetime.now(UTC).isoformat(),
                "reason": "ä»»åŠ¡å·²æˆåŠŸå®Œæˆ!",
            },
        },
        {
            "event_type": "novel.created",
            "data": {
                "id": "novel-demo-456",
                "title": "AI ç¼–å¹´å²",
                "theme": "ç§‘å¹»",
                "status": "draft",
                "created_at": datetime.now(UTC).isoformat(),
            },
        },
    ]

    async with SSETestClient() as client:
        print(f"ğŸ­ æ­£åœ¨ä¸ºç”¨æˆ· {args.user_id} è¿è¡Œ SSE æ¼”ç¤º")
        print(f"ğŸ“¤ å°†å‘é€ {len(test_events)} ä¸ªæµ‹è¯•äº‹ä»¶ï¼Œé—´éš” {args.interval} ç§’...")

        for i, event in enumerate(test_events, 1):
            print(f"\nğŸ“¨ [{i}/{len(test_events)}] å‘é€: {event['event_type']}")

            stream_id = await client.send_event(
                user_id=args.user_id, event_type=event["event_type"], data=event["data"]
            )

            print(f"   âœ… å·²å‘é€ (stream_id: {stream_id})")

            if i < len(test_events):  # æœ€åä¸€ä¸ªäº‹ä»¶ä¸ç­‰å¾…
                print(f"   â±ï¸  ç­‰å¾… {args.interval} ç§’...")
                await asyncio.sleep(args.interval)

        print(f"\nğŸ‰ æ¼”ç¤ºå®Œæˆ! å·²å‘ç”¨æˆ· {args.user_id} å‘é€ {len(test_events)} ä¸ªäº‹ä»¶")
        print("ğŸ’¡ è¯·æ£€æŸ¥å‰ç«¯æ˜¯å¦æ”¶åˆ°è¿™äº›äº‹ä»¶")


async def cmd_unique(args):
    """å‘é€5ä¸ªå®Œå…¨ä¸åŒç±»å‹çš„äº‹ä»¶ï¼ˆç”¨äºæ•…éšœæ’é™¤ï¼‰ã€‚"""
    # 5ä¸ªå®Œå…¨ä¸åŒç±»å‹çš„äº‹ä»¶ï¼Œé¿å…é‡å¤
    unique_events = [
        {
            "event_type": "system.notification-sent",
            "data": {
                "level": "info",
                "title": "ç‹¬ç‰¹æµ‹è¯•1",
                "message": "ç³»ç»Ÿé€šçŸ¥äº‹ä»¶",
                "action_required": False,
            },
        },
        {
            "event_type": "novel.created",
            "data": {
                "id": f"unique-novel-{int(datetime.now(UTC).timestamp())}",
                "title": "ç‹¬ç‰¹æµ‹è¯•å°è¯´",
                "theme": "æµ‹è¯•",
                "status": "draft",
                "created_at": datetime.now(UTC).isoformat(),
            },
        },
        {
            "event_type": "task.status-changed",
            "data": {
                "task_id": f"unique-task-{int(datetime.now(UTC).timestamp())}",
                "old_status": "pending",
                "new_status": "completed",
                "timestamp": datetime.now(UTC).isoformat(),
                "reason": "ç‹¬ç‰¹æµ‹è¯•ä»»åŠ¡å®Œæˆ",
            },
        },
        {
            "event_type": "chapter.draft-created",
            "data": {
                "chapter_id": f"unique-chapter-{int(datetime.now(UTC).timestamp())}",
                "chapter_number": 1,
                "title": "ç‹¬ç‰¹æµ‹è¯•ç« èŠ‚",
                "novel_id": "test-novel",
            },
        },
        {
            "event_type": "content.updated",
            "data": {
                "entity_type": "novel",
                "entity_id": "test-novel",
                "action": "updated",
                "summary": "ç‹¬ç‰¹æµ‹è¯•å†…å®¹æ›´æ–°",
                "changed_fields": ["title", "content"],
            },
        },
    ]

    async with SSETestClient() as client:
        print(f"ğŸ§ª æ­£åœ¨ä¸ºç”¨æˆ· {args.user_id} å‘é€5ä¸ªå®Œå…¨ä¸åŒç±»å‹çš„äº‹ä»¶")
        print(f"ğŸ“¤ äº‹ä»¶é—´éš” {args.interval} ç§’...")

        for i, event in enumerate(unique_events, 1):
            print(f"\nğŸ“¨ [{i}/{len(unique_events)}] å‘é€: {event['event_type']}")

            stream_id = await client.send_event(
                user_id=args.user_id, event_type=event["event_type"], data=event["data"]
            )

            print(f"   âœ… å·²å‘é€ (stream_id: {stream_id})")

            if i < len(unique_events):  # æœ€åä¸€ä¸ªäº‹ä»¶ä¸ç­‰å¾…
                print(f"   â±ï¸  ç­‰å¾… {args.interval} ç§’...")
                await asyncio.sleep(args.interval)

        print(f"\nğŸ‰ ç‹¬ç‰¹æµ‹è¯•å®Œæˆ! å·²å‘é€ {len(unique_events)} ä¸ªä¸åŒç±»å‹çš„äº‹ä»¶")
        print("ğŸ’¡ æ¯ä¸ªäº‹ä»¶ç±»å‹éƒ½ä¸åŒï¼Œåº”è¯¥éƒ½èƒ½è¢«å‰ç«¯æ¥æ”¶")


async def cmd_history(args):
    """æŸ¥çœ‹ç”¨æˆ·çš„ SSE äº‹ä»¶å†å²ã€‚"""
    async with SSETestClient() as client:
        events = await client.get_user_events_history(args.user_id, args.limit)

        if not events:
            print(f"ğŸ“­ ç”¨æˆ· {args.user_id} æš‚æ—  SSE äº‹ä»¶å†å²")
            return

        print(f"ğŸ“š ç”¨æˆ· {args.user_id} çš„æœ€è¿‘ {len(events)} ä¸ª SSE äº‹ä»¶:")
        print()

        for i, event in enumerate(events, 1):
            print(f"[{i}] ID: {event.id}")
            print(f"    äº‹ä»¶: {event.event}")
            print(f"    ä½œç”¨åŸŸ: {event.scope.value}")
            print(f"    æ•°æ®: {json.dumps(event.data, indent=6, ensure_ascii=False)}")
            print()


async def cmd_cleanup(args):
    """æ¸…ç†æ‰€æœ‰ SSE è¿æ¥å’Œäº‹ä»¶æµã€‚"""
    async with SSETestClient() as client:
        if args.dry_run:
            print("ğŸƒ è¿è¡Œæ¨¡å¼: è¯•è¿è¡Œ (ä¸ä¼šå®é™…åˆ é™¤ä»»ä½•æ•°æ®)")
        else:
            print("âš ï¸  è­¦å‘Š: è¿™å°†æ¸…ç†æ‰€æœ‰ SSE äº‹ä»¶æµå’Œè¿æ¥æ•°æ®!")
            print("âš ï¸  è¿™æ˜¯ä¸€ä¸ªç ´åæ€§æ“ä½œï¼Œæ— æ³•æ’¤é”€!")

            if not args.force:
                response = input("ç¡®è®¤è¦ç»§ç»­å—? (è¾“å…¥ 'yes' ç¡®è®¤): ")
                if response.lower() != "yes":
                    print("âŒ æ“ä½œå·²å–æ¶ˆ")
                    return

        print()
        print("ğŸ§¹ å¼€å§‹æ¸…ç† SSE è¿æ¥å’Œäº‹ä»¶æ•°æ®...")

        try:
            stats = await client.cleanup_all_connections(dry_run=args.dry_run)

            print()
            print("ğŸ“Š æ¸…ç†ç»Ÿè®¡:")
            print(f"   ğŸ“¨ SSE äº‹ä»¶æµ: {stats['event_streams_deleted']}")
            print(f"   ğŸ”¢ è¿æ¥è®¡æ•°å™¨: {stats['connection_counters_deleted']}")
            print(f"   ğŸ—‚ï¸  å…¶ä»–é”®: {stats['other_keys_deleted']}")
            print(f"   ğŸ“ˆ æ€»è®¡: {stats['total_deleted']}")

            if args.dry_run:
                print()
                print("âœ… è¯•è¿è¡Œå®Œæˆ - æ²¡æœ‰å®é™…åˆ é™¤ä»»ä½•æ•°æ®")
                print("ğŸ’¡ è¦æ‰§è¡Œå®é™…æ¸…ç†ï¼Œè¯·æ·»åŠ  --force å‚æ•°")
            else:
                print()
                print("âœ… æ¸…ç†å®Œæˆ!")
                if stats["total_deleted"] == 0:
                    print("ğŸ’¡ æ²¡æœ‰æ‰¾åˆ°éœ€è¦æ¸…ç†çš„æ•°æ®")
                else:
                    print("ğŸ’¡ æ‰€æœ‰ SSE ç›¸å…³æ•°æ®å·²æ¸…ç†")

        except Exception as e:
            logger.error(f"âŒ æ¸…ç†å¤±è´¥: {e}")
            print(f"âŒ æ¸…ç†æ“ä½œå¤±è´¥: {e}")
            raise


def main():
    """Main CLI entry point."""
    parser = argparse.ArgumentParser(
        description="SSE Testing CLI Tool",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__,
    )

    # Global options
    parser.add_argument("--debug", action="store_true", help="Enable debug logging")

    subparsers = parser.add_subparsers(dest="command", help="Available commands")

    # Send command
    send_parser = subparsers.add_parser("send", help="å‘é€å•ä¸ªæµ‹è¯• SSE äº‹ä»¶")
    send_parser.add_argument("--user-id", required=True, help="ç›®æ ‡ç”¨æˆ· ID")
    send_parser.add_argument("--event-type", required=True, help="äº‹ä»¶ç±»å‹ (ä¾‹å¦‚: 'test.message')")
    send_parser.add_argument("--data", required=True, help="äº‹ä»¶æ•°æ® (JSON å­—ç¬¦ä¸²)")
    send_parser.add_argument(
        "--scope",
        choices=["user", "session", "novel", "global"],
        default="user",
        help="äº‹ä»¶ä½œç”¨åŸŸ",
    )

    # Demo command
    demo_parser = subparsers.add_parser("demo", help="è¿è¡Œæ¼”ç¤ºæ¨¡å¼ï¼Œå‘é€å¤šä¸ªæµ‹è¯•äº‹ä»¶")
    demo_parser.add_argument("--user-id", required=True, help="ç›®æ ‡ç”¨æˆ· ID")
    demo_parser.add_argument(
        "--interval",
        type=int,
        default=2,
        help="äº‹ä»¶é—´éš”æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤: 2",
    )

    # History command
    history_parser = subparsers.add_parser("history", help="æŸ¥çœ‹ç”¨æˆ·çš„ SSE äº‹ä»¶å†å²")
    history_parser.add_argument("--user-id", required=True, help="ç”¨æˆ· ID")
    history_parser.add_argument(
        "--limit",
        type=int,
        default=10,
        help="æ˜¾ç¤ºæœ€è¿‘çš„äº‹ä»¶æ•°é‡ï¼Œé»˜è®¤: 10",
    )

    # Test unique command - åªå‘é€ä¸åŒç±»å‹çš„äº‹ä»¶
    unique_parser = subparsers.add_parser("unique", help="å‘é€5ä¸ªå®Œå…¨ä¸åŒç±»å‹çš„äº‹ä»¶ï¼ˆç”¨äºæ•…éšœæ’é™¤ï¼‰")
    unique_parser.add_argument("--user-id", required=True, help="ç›®æ ‡ç”¨æˆ· ID")
    unique_parser.add_argument(
        "--interval",
        type=int,
        default=2,
        help="äº‹ä»¶é—´éš”æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤: 2",
    )

    # Cleanup command
    cleanup_parser = subparsers.add_parser("cleanup", help="æ¸…ç†æ‰€æœ‰ SSE è¿æ¥å’Œäº‹ä»¶æµ")
    cleanup_parser.add_argument("--dry-run", action="store_true", help="è¯•è¿è¡Œæ¨¡å¼ï¼Œæ˜¾ç¤ºå°†è¦åˆ é™¤çš„å†…å®¹ä½†ä¸å®é™…åˆ é™¤")
    cleanup_parser.add_argument("--force", action="store_true", help="è·³è¿‡ç¡®è®¤æç¤ºï¼Œç›´æ¥æ‰§è¡Œæ¸…ç†")

    args = parser.parse_args()

    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)

    if not args.command:
        parser.print_help()
        return

    # Run the appropriate command
    try:
        if args.command == "send":
            asyncio.run(cmd_send(args))
        elif args.command == "demo":
            asyncio.run(cmd_demo(args))
        elif args.command == "unique":
            asyncio.run(cmd_unique(args))
        elif args.command == "history":
            asyncio.run(cmd_history(args))
        elif args.command == "cleanup":
            asyncio.run(cmd_cleanup(args))
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æ“ä½œå·²å–æ¶ˆ")
    except Exception as e:
        logger.error(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        if args.debug:
            import traceback

            traceback.print_exc()


if __name__ == "__main__":
    main()
