---
description: Execute spec tasks using TDD methodology
allowed-tools: Bash, Read, Write, Edit, MultiEdit, Grep, Glob, LS, WebFetch
argument-hint: <feature-name> <task-numbers>
---

# 使用TDD执行规范任务

使用Kent Beck的测试驱动开发方法从规范执行实施任务。

## 参数：$ARGUMENTS

## 说明

### 帮助模式（--help）

如果参数包含"--help"，显示用法：

```
/spec-task:impl <功能名称> <任务编号>

示例：
  /spec-task:impl auth-system 1.1            # 执行任务 1.1
  /spec-task:impl auth-system 1,2,3          # 执行任务 1、2、3
  /spec-task:impl auth-system --all          # 执行所有待处理任务
```

### 执行前验证

功能名称：!`echo "$ARGUMENTS" | awk '{print $1}' | head -1`

验证所需文件是否存在：

- 需求：检查 `.tasks/<功能名称>/requirements.md` 是否存在
- 高层设计：检查 `.tasks/<功能名称>/design-hld.md` 是否存在
- 低层设计：检查 `.tasks/<功能名称>/lld/` 目录是否存在
- 任务：检查 `.tasks/<功能名称>/tasks.md` 是否存在
- 元数据：检查 `.tasks/<功能名称>/spec.json` 是否存在

### 上下文加载

**执行前加载所有必需的内容：**

核心指导和自定义指导文件将提供整体项目上下文。

**规范文档：**
功能名称目录：!`echo "$ARGUMENTS" | awk '{print $1}' | head -1`

- 需求：`.tasks/<功能名称>/requirements.md`
- 高层设计：`.tasks/<功能名称>/design-hld.md`
- 低层设计：`.tasks/<功能名称>/lld/` (目录)
- 任务：`.tasks/<功能名称>/tasks.md`

**注意**：<功能名称> 将在执行期间替换为实际的功能名称

【可选：前置规划支持】

**整体技术规划**：
- 若存在 `.tasks/<功能名称>/impl-plan.md` 且在 `spec.json` 中 `impl_plan.approved=true`：
  - 作为权威参考优先加载该文档与 `.tasks/<功能名称>/references/` 缓存（接口签名、示例、坑点）
  - 实现阶段应以此为依据，减少重复检索；若发现偏差，需回写更新 `impl-plan.md`
- 若不存在或未批准：按需即时查询库文档（见下文“库文档查询”），但建议先执行 `/spec-task:impl-plan <功能名称>`

【可选：测试场景支持】

- 若存在 `.tasks/<功能名称>/task-plans/` 目录：
  - 当指定了任务编号 `<id>`：优先尝试加载 `.tasks/<功能名称>/task-plans/task-<id>-test-scenarios.md`
  - 若任务级文件不存在，则回退加载 `.tasks/<功能名称>/task-plans/test-scenarios.md`
  - 加载到的"测试场景"用于 RED 阶段直接转化为测试用例（名称、测试数据、预期结果），以减少歧义并统一断言口径
  - 测试场景由可选命令 `/spec-task:impl-test-scenario` 生成

【可选：测试细节支持】

- 若存在 `.tasks/<功能名称>/task-plans/test-details-<任务编号>.md`：
  - 提供被测对象（SUT）的技术规格
  - 明确构造函数依赖、方法签名、返回类型
  - 定义Mock策略和断言模式
  - 测试细节由可选命令 `/spec-task:impl-test-detail` 生成

**任务级详细规划**：
- 若存在 `.tasks/<功能名称>/task-plans/<任务编号>.md` 且在 `spec.json` 中 `task_plans.<任务编号>.approved=true`：
  - 作为该任务的实施蓝图，严格按照计划的步骤执行
  - 使用计划中定义的测试用例和验收标准
  - 遵循计划中的TDD步骤顺序
- 若不存在或未批准：按照标准TDD流程执行，对复杂任务建议先执行 `/spec-task:impl-task-plan <功能名称> <任务编号>`

### 任务执行

1. **从参数解析功能名称和任务编号**
2. **加载所有上下文**（指导 + 规范文档）
3. **分析当前实现进度**（强制步骤）
4. **初始化任务进度跟踪**（强制步骤）
5. **从tasks.md提取复选框**
6. **直接使用TDD方法执行每个复选框**

### 分析当前实现进度（强制步骤）

在开始任何新任务实现之前，必须先分析当前项目的实现状态：

#### 1. 检查任务完成状态

- **读取 tasks.md**：分析哪些任务已完成 `[x]`，哪些待完成 `[ ]`
- **识别依赖关系**：确定待实现任务是否依赖已完成的组件
- **评估连续性**：确保实现顺序合理，避免跳跃式开发

#### 2. 分析现有代码结构

**后端代码分析**：
- 扫描 `apps/backend/` 目录结构
- 识别已存在的模型、服务、API端点
- 查看已实现的数据库表和迁移
- 分析现有的依赖注入和配置

**前端代码分析**（如适用）：
- 扫描 `apps/frontend/` 目录结构  
- 识别已存在的组件、页面、服务
- 查看状态管理和路由配置
- 分析现有的API集成方式

#### 3. 评估集成点和接口

- **API接口一致性**：检查现有API设计模式和命名约定
- **数据库设计连贯性**：确保新表/字段与现有结构兼容
- **组件复用机会**：识别可复用的现有组件和服务
- **配置和环境变量**：了解现有的配置模式

#### 4. 识别技术债务和模式

- **代码质量评估**：了解现有代码的质量水平和规范
- **测试覆盖状况**：查看现有测试的结构和模式
- **错误处理模式**：学习项目的错误处理约定
- **日志和监控**：了解现有的可观测性实现

#### 5. 生成实现上下文报告

基于上述分析，生成一个简洁的实现上下文报告：

```markdown
## 当前实现进度分析

### 已完成任务
- [x] 任务 1.1: [描述]
- [x] 任务 1.2: [描述]

### 待实现任务  
- [ ] 任务 2.1: [描述] - **当前目标**
- [ ] 任务 2.2: [描述]

### 现有技术栈
- 后端框架: [已使用的框架和版本]
- 数据库: [已创建的表和关系]
- API设计: [现有API的模式和约定]

### 可复用组件
- [现有组件1]: [用途和接口]
- [现有服务2]: [功能和使用方式]

### 技术约定
- [错误处理]: [现有模式]
- [测试结构]: [测试组织方式]
- [配置管理]: [配置加载方式]

### 集成注意点
- [依赖关系]: [需要注意的依赖]
- [接口兼容]: [需要保持的接口规范]
- [数据一致性]: [数据模型约束]
```

#### 6. 确定实现策略

基于进度分析结果：
- **确定起点**：从哪个组件或功能开始实现
- **复用策略**：如何利用现有代码和组件
- **集成方式**：如何与已有系统集成
- **测试策略**：如何与现有测试集成

### 初始化任务进度跟踪（强制步骤）

每个任务必须创建和维护独立的进度跟踪文件：

#### 1. 进度文件路径和命名

- **文件路径**：`.tasks/<功能名称>/progress/task-<任务编号>.md`
- **文件名格式**：`task-1.1.md`、`task-2.3.md`、`task-all.md`（批量执行时）
- **目录创建**：如果 `progress/` 目录不存在，自动创建

#### 2. 任务开始时的进度文件处理

**检查现有进度**：
```bash
# 检查是否存在现有进度文件
if [ -f ".tasks/<功能名称>/progress/task-<任务编号>.md" ]; then
    # 读取现有进度
    # 分析已完成的步骤
    # 确定继续点
else
    # 创建新的进度文件
fi
```

**现有进度文件存在时**：
- **读取进度状态**：分析已完成的TDD步骤和子任务
- **检查中断点**：识别最后完成的步骤和当前状态
- **验证一致性**：确保代码状态与记录的进度一致
- **继续或重新开始**：
  - 如果进度完整且代码一致：从中断点继续
  - 如果发现不一致：提示用户选择重新开始或手动修复

**进度文件不存在时**：
- 创建新的进度跟踪文件
- 初始化任务元数据和状态

#### 3. 进度文件模板

```markdown
# Task Progress: <任务编号> - <任务描述>

**功能名称**: <功能名称>  
**任务编号**: <任务编号>  
**开始时间**: <时间戳>  
**当前状态**: <进行中|已完成|暂停|失败>  
**完成进度**: <X>/<总步数>

## 任务描述

<从 tasks.md 提取的任务描述>

## 实现策略

基于实现进度分析：
- **复用组件**: <识别的可复用组件>
- **集成方式**: <与现有系统的集成策略>
- **测试策略**: <测试方法和模式>

## TDD 实施进度

### 步骤 1: 库文档查询 ⏳
- **状态**: <待开始|进行中|已完成>
- **开始时间**: <时间戳>
- **完成时间**: <时间戳>
- **查询的库**: 
  - [ ] FastAPI (版本: x.x.x)
  - [ ] SQLAlchemy 
  - [ ] Pydantic
- **获得的接口信息**: <关键接口和方法签名>
- **注意事项**: <重要发现和注意点>

### 步骤 2: 红灯阶段（RED）⏳
- **状态**: <待开始|进行中|已完成>
- **开始时间**: <时间戳>
- **完成时间**: <时间戳>
- **测试用例**:
  - [ ] `test_<功能>_<场景1>()`
  - [ ] `test_<功能>_<场景2>()`
- **测试场景**: <基于测试场景文档的具体场景>
- **失败原因**: <预期的失败原因>
- **代码位置**: <测试文件路径>

### 步骤 3: 绿灯阶段（GREEN）⏳
- **状态**: <待开始|进行中|已完成>
- **开始时间**: <时间戳>
- **完成时间**: <时间戳>
- **实现内容**:
  - [ ] 创建/修改模型: <文件路径>
  - [ ] 实现服务方法: <方法名和文件>
  - [ ] 添加API端点: <端点路径>
- **使用的库接口**: <实际使用的API调用>
- **代码位置**: <实现文件路径列表>
- **测试状态**: <所有测试是否通过>

### 步骤 4: 重构阶段（REFACTOR）⏳
- **状态**: <待开始|进行中|已完成>
- **开始时间**: <时间戳>
- **完成时间**: <时间戳>
- **重构内容**:
  - [ ] 提取公共逻辑: <详细说明>
  - [ ] 优化性能: <具体优化>
  - [ ] 改善可读性: <改进点>
- **重构后测试**: <所有测试仍然通过>

### 步骤 5: 质量验证⏳
- **状态**: <待开始|进行中|已完成>
- **开始时间**: <时间戳>
- **完成时间**: <时间戳>
- **code-simplifier 验证**:
  - **状态**: <通过|失败|待验证>
  - **反馈**: <代理提供的反馈>
  - **修复内容**: <根据反馈的修复>
- **code-review-expert 验证**:
  - **状态**: <通过|失败|待验证>
  - **反馈**: <代理提供的反馈>
  - **修复内容**: <根据反馈的修复>

## 问题和决策记录

### 遇到的问题
1. **问题**: <具体问题描述>
   - **时间**: <时间戳>
   - **解决方案**: <采取的解决方案>
   - **影响**: <对进度的影响>

### 技术决策
1. **决策**: <具体技术决策>
   - **原因**: <决策原因>
   - **替代方案**: <考虑过的其他选择>
   - **影响**: <对后续开发的影响>

## 代码变更记录

### 新增文件
- `<文件路径>`: <文件用途和主要内容>

### 修改文件  
- `<文件路径>`: <修改内容和原因>

### 测试文件
- `<测试文件路径>`: <测试覆盖范围>

## 最终状态

- **任务状态**: <已完成|失败>
- **完成时间**: <时间戳>
- **tasks.md 更新**: <是否已更新复选框为 [x]>
- **测试通过**: <所有测试是否通过>
- **质量验证**: <两个代理是否都通过>
- **集成验证**: <与现有代码是否兼容>

---
*最后更新: <时间戳>*
```

#### 4. 进度更新频率

**必须更新进度的时机**：
1. **任务开始时** - 创建/更新进度文件
2. **每个TDD步骤开始时** - 更新步骤状态为"进行中"
3. **每个TDD步骤完成时** - 更新步骤状态为"已完成"，记录结果
4. **遇到问题时** - 记录问题和解决方案
5. **做出技术决策时** - 记录决策原因和影响
6. **任务完成时** - 更新最终状态

#### 5. 进度文件的使用

**中断恢复**：
- 分析最后完成的步骤
- 验证代码状态与记录一致性
- 从正确的点继续实施

**问题排查**：
- 查看问题记录和解决方案
- 了解技术决策的上下文
- 追踪代码变更历史

**进度报告**：
- 快速了解任务完成情况
- 识别阻塞点和风险
- 评估剩余工作量

### 对于每个任务复选框

直接使用TDD方法执行：

**实施步骤：**

1. **加载项目上下文和初始化进度跟踪**：
   - 规范元数据：`.tasks/<功能名称>/spec.json`
   - 需求：`.tasks/<功能名称>/requirements.md`
   - 高层设计：`.tasks/<功能名称>/design-hld.md`
   - 低层设计：`.tasks/<功能名称>/lld/` (目录)
   - 所有任务：`.tasks/<功能名称>/tasks.md`
   - **分析现有实现**：扫描项目结构，生成实现上下文报告（见上述步骤）
   - **检查任务进度**：读取 `.tasks/<功能名称>/progress/task-<任务编号>.md`（如存在）
   - **初始化进度跟踪**：创建或更新进度文件，记录任务开始状态
   - 任务计划（如果存在）：`.tasks/<功能名称>/task-plans/<任务编号>.md`
   - 测试细节（如果存在）：`.tasks/<功能名称>/task-plans/test-details-<任务编号>.md`

2. **针对每个特定任务的TDD实施**：
   - **基于实现进度分析制定策略**：
     - 利用已识别的可复用组件和服务
     - 遵循现有的代码模式和技术约定
     - 确保与现有API和数据模型的兼容性
     - 复用现有的测试结构和模式
   - **优先使用测试场景（若存在）**：
     - 从 `task-plans/task-<id>-test-scenarios.md` 或 `task-plans/test-scenarios.md` 提取场景条目
     - 将每个场景转化为一个独立的测试用例（RED），使用场景中的"测试数据"和"预期结果"作为断言依据
   - **应用测试细节（若存在）**：
     - 从 `test-details-<id>.md` 获取 SUT 类名、构造函数依赖、方法签名
     - 使用定义的 Mock 策略和断言模式
     - 按照测试实现模板结构编写测试代码
   - **库文档查询（必需）**：
     - 更新进度文件：步骤1状态→"进行中"
     - 使用 context7 获取任务中涉及库的最新接口、方法签名和调用示例（若 impl-plan 已批准且 references 可用则优先引用）
     - 更新进度文件：记录查询的库、获得的接口信息、注意事项
     - 更新进度文件：步骤1状态→"已完成"
   - **红灯（RED）**：
     - 更新进度文件：步骤2状态→"进行中"
     - 首先编写失败的测试，结合测试场景数据、测试细节规格和现有测试模式
     - 更新进度文件：记录测试用例、测试场景、失败原因、代码位置
     - 更新进度文件：步骤2状态→"已完成"
   - **绿灯（GREEN）**：
     - 更新进度文件：步骤3状态→"进行中"
     - 编写最少的代码使测试通过，使用从 context7 获取的准确接口，并与现有代码保持一致性
     - 更新进度文件：记录实现内容、使用的库接口、代码位置、测试状态
     - 更新进度文件：步骤3状态→"已完成"
   - **重构（REFACTOR）**：
     - 更新进度文件：步骤4状态→"进行中"
     - 清理和改进代码结构，遵循库的最佳实践和项目现有模式
     - 更新进度文件：记录重构内容、重构后测试状态
     - 更新进度文件：步骤4状态→"已完成"

3. **任务完成**：
   - 验证所有测试通过
   - **强制质量检验**：
     - 更新进度文件：步骤5状态→"进行中" 
     - 使用 **code-simplifier** 代理检查代码复杂度并简化重构
     - 更新进度文件：记录 code-simplifier 验证状态和反馈
     - 根据反馈修复问题（如有）
     - 使用 **code-review-expert** 代理进行代码质量审查
     - 更新进度文件：记录 code-review-expert 验证状态和反馈
     - 根据反馈修复问题（如有）
     - 更新进度文件：步骤5状态→"已完成"
   - **最终状态更新**：
     - 更新进度文件：任务状态→"已完成"，记录完成时间
     - 更新进度文件：记录所有代码变更和测试文件
     - 在 .tasks/<功能名称>/tasks.md 中将复选框从 `- [ ]` 更新为 `- [x]`
     - 更新进度文件：确认 tasks.md 已更新
   - 确保现有测试没有回归
   - **遇到问题时**：随时更新进度文件的"问题和决策记录"部分

**对于每个任务：**

- 从 tasks.md 提取确切的复选框内容
- 严格遵循 Kent Beck 的 TDD 方法
- 仅实施特定的任务需求
- 保持代码质量和测试覆盖率

## 实施逻辑

1. **解析参数**：
   - 功能名称：第一个参数
   - 任务编号：第二个参数（支持："1"、"1,2,3"、"--all"）

2. **验证**：
   - 规范目录存在
   - 必需文件（requirements.md、design-hld.md、lld/目录、tasks.md、spec.json）存在
   - 规范已批准可以实施

3. **执行**：
   - **首先将所有文件内容加载到内存中**
   - **构建完整的实施上下文**
   - **强制执行实现进度分析**：扫描项目结构，分析已完成任务，生成实现上下文报告
   - **初始化任务进度跟踪**：创建 `progress/task-<任务编号>.md` 文件，记录初始状态
   - **库文档准备**：对于每个任务，使用 context7 获取所需库的详细文档和接口信息
   - **使用TDD方法按顺序执行每个任务**，在每个步骤完成时更新进度文件
   - 每个任务实施都接收完整的项目知识、当前实现状态、准确的库接口信息和任务进度状态

## 错误处理

- 未找到规范：先运行 /spec-task:init
- 未批准：先完成规范工作流
- 任务失败：保持复选框未选中，显示错误

## 成功指标

- 实现进度分析已完成并生成上下文报告
- 任务进度文件已创建和持续更新
- tasks.md 中所有选定的复选框都标记为 [x]
- 所有测试通过
- 新代码与现有代码保持一致性和兼容性
- 代码通过质量审查（通过 code-review-expert 代理验证）
- 代码复杂度符合标准（通过 code-simplifier 代理验证和优化）
- 进度文件中所有5个TDD步骤都标记为"已完成"
- 进度文件记录了完整的代码变更和问题解决过程
- 没有回归

---

## TDD方法详解

### 测试驱动开发核心原则

**TDD三步循环：**

1. **红灯阶段（Red）**
   - 编写一个失败的测试
   - 测试应该描述期望的行为
   - 运行测试确认它失败（因为功能还未实现）

2. **绿灯阶段（Green）**
   - 编写最少的代码使测试通过
   - 不要过度设计或优化
   - 目标是快速使测试变绿

3. **重构阶段（Refactor）**
   - 在测试保护下改进代码
   - 消除重复，提高可读性
   - 确保所有测试仍然通过

### TDD最佳实践

**库文档查询原则（强制要求）：**

- 在编写测试前，必须使用 context7 获取相关库的接口文档
- 确保使用的方法签名和参数与最新文档一致
- 获取库的最佳实践和常见使用模式
- 了解库的错误处理和异常情况

**测试编写原则：**

- 一次只编写一个测试
- 测试应该简单、独立、可重复
- 使用描述性的测试名称
- 遵循 Arrange-Act-Assert 模式
- 基于 context7 获取的接口信息编写准确的测试

**代码实施原则：**

- 从最简单的测试案例开始
- 逐步增加复杂性
- 保持测试和生产代码的平衡
- 频繁运行测试套件

**重构指导：**

- 仅在所有测试通过后重构
- 小步重构，频繁验证
- 关注代码的可读性和可维护性
- 应用SOLID原则和设计模式

### 任务执行流程示例

```
任务：实现用户认证系统

0. 初始化任务进度跟踪：
   - 创建 `.tasks/user-auth/progress/task-2.1.md` 文件
   - 记录任务开始时间和初始状态

1. 实现进度分析：评估当前项目状态
   - 检查已完成任务：[x] 任务 1.1: 数据库初始化, [x] 任务 1.2: 基础API结构
   - 分析现有代码：已有 User 基础模型，FastAPI 已配置，SQLAlchemy 已集成
   - 识别可复用组件：数据库连接工具，API 响应格式，错误处理中间件
   - 确定集成策略：复用现有 API 模式，扩展 User 模型，使用现有错误处理
   - 更新进度文件：记录实现策略

2. 库文档查询：使用 context7 获取库信息
   - 更新进度文件：步骤1 → "进行中"
   - 查询 FastAPI 的认证相关接口（基于现有 FastAPI 版本）
   - 获取 SQLAlchemy 的用户模型最佳实践
   - 了解 bcrypt 的密码哈希方法签名
   - 查看 Pydantic 的验证模式
   - 更新进度文件：记录查询结果和接口信息
   - 更新进度文件：步骤1 → "已完成"

3. 红灯：编写测试
   - 更新进度文件：步骤2 → "进行中"
   - test_user_can_register()
   - 基于 context7 文档使用正确的接口，复用现有测试模式
   - 预期：用户可以成功注册
   - 结果：测试失败（功能未实现）
   - 更新进度文件：记录测试用例和失败原因
   - 更新进度文件：步骤2 → "已完成"

4. 绿灯：实现功能
   - 更新进度文件：步骤3 → "进行中"
   - 扩展现有 User 模型（保持与现有结构的一致性）
   - 实现 register() 方法（使用 bcrypt 正确接口）
   - 复用现有的 API 响应格式和错误处理
   - 结果：测试通过
   - 更新进度文件：记录实现内容和代码位置
   - 更新进度文件：步骤3 → "已完成"

5. 重构：改进代码
   - 更新进度文件：步骤4 → "进行中"
   - 提取验证逻辑（遵循项目现有的 Pydantic 模式）
   - 使用现有的错误处理中间件
   - 优化数据库查询（遵循项目现有模式）
   - 结果：测试仍然通过，代码更清晰且与项目一致
   - 更新进度文件：记录重构内容
   - 更新进度文件：步骤4 → "已完成"

6. 最终质量验证（强制要求）：
   - 更新进度文件：步骤5 → "进行中"
   - 使用 code-simplifier 代理：检查并简化代码复杂度
   - 更新进度文件：记录简化验证结果
   - 使用 code-review-expert 代理：审查代码质量和规范
   - 更新进度文件：记录质量审查结果
   - 结果：所有代理验证通过，任务标记为完成
   - 更新进度文件：步骤5 → "已完成"

7. 完成任务：
   - 更新进度文件：任务状态 → "已完成"
   - 更新进度文件：记录所有代码变更文件
   - 在 tasks.md 中标记任务为 [x]
   - 更新进度文件：确认 tasks.md 已更新
```

### 测试覆盖率要求

- 单元测试：核心业务逻辑 > 80%
- 集成测试：关键流程 100%
- 端到端测试：主要用户场景覆盖

### 持续集成注意事项

- 每次提交前运行所有测试
- 保持测试套件快速执行
- 修复失败的测试是最高优先级
- 维护测试环境的一致性

---

## 最终质量验证流程（强制要求）

每个任务完成后，必须按顺序使用以下两个专门代理进行质量验证：

### 1. 代码简化验证 (code-simplifier)

**用途**：检查代码复杂度并进行简化重构

**执行时机**：TDD 重构阶段完成后

**验证内容**：

- 检查函数和类的复杂度是否过高
- 识别重复代码和可提取的公共逻辑
- 简化过度复杂的条件逻辑
- 优化代码结构和可读性
- 确保遵循项目的代码约定

**通过标准**：

- 函数复杂度在合理范围内
- 无明显的代码重复
- 代码结构清晰易懂
- 遵循 SOLID 原则

### 2. 代码质量审查 (code-review-expert)

**用途**：进行综合代码质量审查

**执行时机**：代码简化完成后

**审查内容**：

- 代码风格和规范一致性
- 错误处理和边界条件
- 安全性考虑
- 性能潜在问题
- 可维护性和可扩展性
- API 设计合理性
- 文档和注释质量

**通过标准**：

- 代码符合项目规范
- 错误处理完善
- 无明显安全隐患
- 性能表现良好
- 具备良好的可维护性


### 代理验证执行流程

```
任务实施完成 →
1. 使用 code-simplifier 代理简化优化代码 →
2. 使用 code-review-expert 代理审查代码质量 →
3. 所有验证通过后，标记任务为完成 [x]
```

### 验证失败处理

如果任何一个代理验证失败：

- **不要标记任务为完成**
- 根据代理反馈修复问题
- 重新运行失败的代理验证
- 确保所有两个代理都通过后才能完成任务

### 质量门控标准

只有当所有两个代理验证都通过时，任务才能被标记为完成：

- ✅ code-simplifier: 代码简洁性通过
- ✅ code-review-expert: 代码质量通过
