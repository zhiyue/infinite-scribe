<!-- Generated by SpecStory -->

# From Background: Implement command-based API and transactional outbox (2025-07-04 21:42Z)

_**User**_

# Story 2.2: 实现基于命令的创世API和事务性发件箱

## Status: Approved

## Story

- As a 前端开发者
- I want 一组基于命令模式的API端点来驱动创世流程, 并且后端能保证事件发布的原子性
- so that 我可以用统一的方式与后端交互，并信任系统的可靠性

## Acceptance Criteria (ACs)

1. **[Given]** API网关 **[When]** 接收到一个 `POST /.../commands` 请求 **[Then]** 它必须能够根据请求体中的 `command_type` 路由到不同的处理逻辑。
2. **[When]** API处理一个命令时 **[Then]** 对`command_inbox`, `domain_events`, 和 `event_outbox` 表的写入操作必须在一个单一的数据库事务中完成。
3. **[When]** 一个重复的、尚未完成的命令被提交 **[Then]** API必须利用`command_inbox`的唯一性约束，返回 `409 Conflict` 状态码，响应体格式为：`{"error_code": "DUPLICATE_COMMAND", "message": "Command already processing", "duplicate_command_id": "uuid"}`。
4. **[Given]** 一个独立的 `Message Relay` 服务 **[When]** `event_outbox` 表中存在 `PENDING` 状态的记录 **[Then]** 该服务必须能够轮询到该记录，将其发布到Kafka，并在成功后将记录状态更新为 `SENT`。
5. **[When]** Message Relay服务在指数退避重试（3次，间隔1s/2s/4s）后仍无法发布事件 **[Then]** 必须将该记录状态更新为 `FAILED` 并记录错误详情。

## Dev Technical Guidance

### Previous Story Insights
- Story 2.1已批准，定义了六张核心表的数据模型：`domain_events`, `command_inbox`, `async_tasks`, `event_outbox`, `flow_resume_handles`, `genesis_sessions`
- 数据库迁移脚本应已在 `infrastructure/docker/init/postgres/20-migration-event-sourcing.sql` 创建
- Pydantic模型应已在 `packages/shared-types/src/models_db.py` 创建
- PostgreSQL运行在192.168.2.201:5432，数据库名infinite_scribe

### Data Models
**命令和事件相关表结构** [Source: architecture/database-schema.md#L155-219]：

- **command_inbox表**: 
  - 包含唯一性约束索引 `idx_command_inbox_unique_pending_command ON command_inbox (session_id, command_type) WHERE status IN ('RECEIVED', 'PROCESSING')`
  - 字段：id, session_id, command_type, idempotency_key, payload, status, created_at

- **domain_events表**:
  - 自增主键确保严格顺序，包含event_id (UUID), correlation_id, causation_id, event_type, event_version, aggregate_type, aggregate_id, payload, metadata, created_at
  - 是整个系统所有业务事实的唯一、不可变来源

- **event_outbox表**:
  - 字段：id, topic, key, payload, status (PENDING/SENT), created_at
  - 用于保证数据库写入与向Kafka发布事件之间的原子性

**Genesis Session模型** [Source: architecture/data-models.md#L94-109]:
- 状态：IN_PROGRESS, COMPLETED, ABANDONED
- 阶段：CONCEPT_SELECTION, STORY_CONCEPTION, WORLDVIEW, CHARACTERS, PLOT_OUTLINE, FINISHED

### API Specifications
**命令端点规范** [Source: architecture/rest-api-spec.md#L330-361]:
- 端点：`POST /genesis/sessions/{session_id}/commands`
- 请求体：CommandRequest { command_type: string, payload: object }
- 响应：
  - 200 OK - 同步命令成功执行
  - 202 Accepted - 异步命令已接受
  - 409 Conflict - 命令冲突（重复命令）

**通用命令处理模式** [Source: architecture/rest-api-spec.md#L10-16]:
- 所有需要后台处理的用户意图通过统一的命令端点发送
- 异步操作返回202 Accepted
- 客户端通过SSE接收实时更新

### Component Specifications
- FastAPI路由应位于：`apps/backend/src/api/routes/v1/genesis.py` [Source: architecture/source-tree.md#L48]
- 命令处理器应位于：`apps/backend/src/common/services/command_service.py`
  - API签名：`async def process_command(session_id: UUID, command_type: str, payload: dict, db: AsyncSession) -> CommandResult`
  - 返回：`CommandResult(command_id: UUID, status: str, message: str)`
- 事件发布服务：`apps/backend/src/common/services/event_publisher.py`
  - API签名：`async def save_to_outbox(topic: str, key: str, payload: dict, db: AsyncSession) -> UUID`
  - 必须验证事件包含correlation_id和causation_id
- Message Relay服务：`apps/backend/src/agents/message_relay/main.py`
  - 轮询频率：每5秒（可通过环境变量RELAY_POLL_INTERVAL配置）
  - 批量大小：100条记录（可通过环境变量RELAY_BATCH_SIZE配置）

### File Locations
- API路由：`apps/backend/src/api/routes/v1/genesis.py`
- 命令服务：`apps/backend/src/common/services/command_service.py`
- 事件发布服务：`apps/backend/src/common/services/event_publisher.py`
- Message Relay服务入口：`apps/backend/src/agents/message_relay/main.py`
- 数据库连接配置：`apps/backend/src/core/database.py` [Source: architecture/source-tree.md#L64]
- Kafka配置：`apps/backend/src/core/messaging.py` [Source: architecture/source-tree.md#L65]

### Testing Requirements
- 使用Pytest进行单元测试 [Source: architecture/test-strategy-and-standards.md#L22]
- 集成测试使用testcontainers启动临时PostgreSQL和Kafka实例 [Source: architecture/test-strategy-and-standards.md#L29]
- 测试覆盖率目标：85% [Source: architecture/test-strategy-and-standards.md#L5]

### Technical Constraints
- FastAPI版本：~0.115.13 [Source: architecture/tech-stack.md#L19]
- Pydantic版本：~2.11.7 [Source: architecture/tech-stack.md#L20]
- Apache Kafka版本：3.7.0 [Source: architecture/tech-stack.md#L22]
- 数据库客户端：使用SQLAlchemy 2.x async模式，保持与现有database.py的一致性
- 事务隔离级别：默认使用PostgreSQL的REPEATABLE READ级别
- 所有事件必须遵循命名规范：`<Domain>.<AggregateRoot>.<OptionalSubAggregate>.<ActionInPastTense>` [Source: architecture/event-naming-conventions.md#L9]
- 使用官方动词表：Requested, Created, Proposed, Submitted, Confirmed, Updated, Revised, Completed, Finished, Failed [Source: architecture/event-naming-conventions.md#L25-41]
- 安全要求：命令端点需要JWT认证（使用Bearer token）[Source: architecture/rest-api-spec.md#L266-273]
- 性能目标：系统应支持每秒至少100个命令请求的处理能力

## Tasks / Subtasks

- [ ] Task 1: 创建命令路由和基础架构 (AC: 1)
  - [ ] 创建 `apps/backend/src/api/routes/v1/genesis.py` 文件
  - [ ] 实现 `POST /genesis/sessions/{session_id}/commands` 端点
  - [ ] 创建CommandRequest和CommandResponse的Pydantic模型
  - [ ] 实现基于command_type的路由分发逻辑

- [ ] Task 2: 实现事务性命令处理服务 (AC: 2, 3)
  - [ ] 创建 `apps/backend/src/common/services/command_service.py`
  - [ ] 实现事务管理器，确保command_inbox、domain_events、event_outbox的原子写入
  - [ ] 实现幂等性检查，利用command_inbox的唯一性约束
  - [ ] 处理409 Conflict响应的逻辑
  - [ ] 实现UniqueViolation异常到HTTPException(409)的映射
  - [ ] 为每个命令生成正确的领域事件（遵循命名规范）
  - [ ] 添加事件命名验证器，确保符合官方动词表

- [ ] Task 3: 实现事件发布服务 (AC: 2)
  - [ ] 创建 `apps/backend/src/common/services/event_publisher.py`
  - [ ] 实现将事件写入event_outbox表的逻辑
  - [ ] 确保事件包含所有必需的元数据字段（event_id, correlation_id, causation_id等）
  - [ ] 添加单元测试验证save_to_outbox的正确性
  - [ ] 实现事件payload和metadata的完整性验证

- [ ] Task 4: 实现Message Relay服务 (AC: 4, 5)
  - [ ] 创建 `apps/backend/src/agents/message_relay/` 目录结构
  - [ ] 创建 `apps/backend/src/agents/message_relay/main.py` 服务入口
  - [ ] 实现定期轮询event_outbox表中PENDING记录的逻辑
  - [ ] 实现Kafka生产者，将事件发布到相应主题
  - [ ] 实现成功发布后更新记录状态为SENT的逻辑
  - [ ] 实现指数退避重试策略（3次，间隔1s/2s/4s）
  - [ ] 实现失败后更新记录状态为FAILED并记录错误详情
  - [ ] 添加SERVICE_TYPE=message-relay的环境变量支持
  - [ ] 实现优雅关闭机制，防止消息丢失

- [ ] Task 5: 集成数据库和Kafka配置 (AC: 2, 4)
  - [ ] 更新 `apps/backend/src/core/database.py` 添加事务支持
  - [ ] 更新 `apps/backend/src/core/messaging.py` 添加Kafka生产者配置
  - [ ] 确保所有数据库操作使用正确的连接池

- [ ] Task 6: 编写单元测试 (AC: 1, 2, 3)
  - [ ] 创建 `apps/backend/tests/unit/api/test_genesis_commands.py`
  - [ ] 创建 `apps/backend/tests/unit/services/test_command_service.py`
  - [ ] 创建 `apps/backend/tests/unit/services/test_event_publisher.py`
  - [ ] 测试命令路由逻辑
  - [ ] 测试幂等性检查和409响应格式
  - [ ] 模拟数据库事务的成功和失败场景
  - [ ] 测试事件命名验证器

- [ ] Task 7: 编写集成测试 (AC: 4, 5)
  - [ ] 创建 `apps/backend/tests/integration/test_message_relay.py`
  - [ ] 创建测试基类，自动运行migration脚本（20-migration-event-sourcing.sql）
  - [ ] 使用testcontainers启动PostgreSQL和Kafka
  - [ ] 测试完整的命令→事件→Kafka流程
  - [ ] 验证事务性保证
  - [ ] 测试Message Relay的重试和失败处理机制
  - [ ] 运行覆盖率测试：`pytest --cov=apps/backend/src --cov-report=html`

### Deviation Analysis
本故事严格遵循Epic要求，实现了基于命令模式的API和事务性发件箱模式。所有技术细节均来自架构文档，确保与系统设计的一致性。

## Dev Notes

### 关键实现细节

1. **命令类型示例**（基于创世流程）：
   - `RequestConceptGeneration` - 请求生成立意选项
   - `ConfirmStage` - 确认当前阶段并进入下一阶段
   - `SubmitFeedback` - 提交用户反馈

2. **事件类型示例**（遵循命名规范）：
   - `Genesis.Session.ConceptGenerationRequested`
   - `Genesis.Session.StageConfirmed`
   - `Genesis.Session.FeedbackSubmitted`

3. **事务处理伪代码**：
   ```python
   from sqlalchemy.exc import IntegrityError
   from asyncpg.exceptions import UniqueViolationError
   
   try:
       async with db.begin():  # 开始事务
           # 1. 插入command_inbox（触发唯一性约束检查）
           cmd = await insert_command_inbox(session_id, command_type, payload, db)
           
           # 2. 插入domain_events
           event = await insert_domain_event(
               event_type=f"Genesis.Session.{command_type}",
               aggregate_id=str(session_id),
               aggregate_type="GENESIS_SESSION",
               correlation_id=cmd.id,
               causation_id=previous_event_id,
               payload=event_payload,
               metadata={"user_id": current_user_id, "source_service": "api-gateway"}
           )
           
           # 3. 插入event_outbox
           await save_to_outbox(
               topic="domain-events", 
               key=str(session_id),
               payload=event.dict(),
               db=db
           )
   except (IntegrityError, UniqueViolationError) as e:
       # 幂等性冲突
       raise HTTPException(
           status_code=409,
           detail={
               "error_code": "DUPLICATE_COMMAND",
               "message": "Command already processing",
               "duplicate_command_id": str(existing_cmd_id)
           }
       )
   except Exception as e:
       # 其他错误，事务自动回滚
       logger.error(f"Transaction failed: {e}")
       raise HTTPException(status_code=500, detail="Internal server error")
   ```

4. **完整的domain_events记录示例**：
   ```json
   {
     "event_id": "550e8400-e29b-41d4-a716-446655440000",
     "correlation_id": "command-inbox-id-uuid",
     "causation_id": "previous-event-uuid-or-null",
     "event_type": "Genesis.Session.ConceptGenerationRequested",
     "event_version": 1,
     "aggregate_type": "GENESIS_SESSION",
     "aggregate_id": "session-uuid",
     "payload": {
       "session_id": "session-uuid",
       "request_params": {
         "theme_preferences": ["科幻", "悬疑"],
         "style_preferences": ["快节奏", "第一人称"]
       }
     },
     "metadata": {
       "user_id": "user-uuid",
       "source_service": "api-gateway",
       "timestamp": "2024-01-01T10:00:00Z",
       "request_id": "req-uuid"
     },
     "created_at": "2024-01-01T10:00:00Z"
   }
   ```

5. **Message Relay服务关键点**：
   - 使用定时任务（默认每5秒）轮询event_outbox
   - 批量处理以提高效率（默认100条/批）
   - 实现优雅关闭，确保不丢失正在处理的消息
   - 重试策略：1s → 2s → 4s → 标记为FAILED
   - Kafka主题命名：使用"domain-events"作为统一主题

### Testing

Dev Note: Story Requires the following tests:

- [ ] Pytest Unit Tests: (nextToFile: false), coverage requirement: 85%
  - 位置：`apps/backend/tests/unit/api/test_genesis_commands.py`
  - 位置：`apps/backend/tests/unit/services/test_command_service.py`
  - 位置：`apps/backend/tests/unit/services/test_event_publisher.py`
  - 位置：`apps/backend/tests/unit/agents/test_message_relay.py`

- [ ] Pytest Integration Test: location: `apps/backend/tests/integration/`
  - `test_command_to_event_flow.py` - 完整的命令处理流程
  - `test_message_relay.py` - Message Relay服务集成测试
  - 使用testcontainers启动PostgreSQL和Kafka
  - 验证端到端的命令处理和事件发布流程
  - 运行覆盖率：`pytest apps/backend/tests/ --cov=apps/backend/src --cov-report=html --cov-report=term-missing`

Manual Test Steps:
1. 启动本地开发环境（PostgreSQL、Kafka、API Gateway）
2. 使用curl或Postman发送命令请求：
   ```bash
   curl -X POST http://localhost:8000/genesis/sessions/{session_id}/commands \
     -H "Content-Type: application/json" \
     -d '{"command_type": "RequestConceptGeneration", "payload": {}}'
   ```
3. 验证返回202 Accepted
4. 检查数据库中command_inbox、domain_events、event_outbox表的记录
5. 启动Message Relay服务，验证事件被发布到Kafka
6. 重复发送相同命令，验证返回409 Conflict

## Dev Agent Record

### Agent Model Used: {{Agent Model Name/Version}}

### Debug Log References

[[LLM: (Dev Agent) If the debug is logged to during the current story progress, create a table with the debug log and the specific task section in the debug log - do not repeat all the details in the story]]

### Completion Notes List

[[LLM: (Dev Agent) Anything the SM needs to know that deviated from the story that might impact drafting the next story.]]

### File List

[[LLM: (Dev Agent) List every new file created, or existing file modified in a bullet list.]]

### Change Log

[[LLM: (Dev Agent) Track document versions and changes during development that deviate from story dev start]]

| Date | Version | Description | Author |
| :--- | :------ | :---------- | :----- |

## QA Results

[[LLM: QA Agent Results]]

---

_**Assistant**_



---



---

完美！现在让我验证最终结果：

---



---



---

I've reviewed the comprehensive conversation summary you provided. This appears to be a well-documented software development project that successfully implemented a command-based Genesis API with transactional outbox pattern. Here are my observations:

## Strong Points of the Project

### 1. **Methodical TDD Approach**
- Clear red-green-refactor cycle implementation
- Comprehensive test coverage with both unit and integration tests
- Proper separation of concerns in testing

### 2. **Excellent Code Review Process**
- Identified critical issues systematically
- Addressed both technical debt and architectural concerns
- Prioritized fixes based on impact (Critical → Structural → Performance)

### 3. **Production-Ready Architecture**
- Proper layering (Core → Services → API → Background Services)
- Transactional guarantees with idempotency
- Event sourcing with proper causation chains
- High-concurrency design considerations

### 4. **File Size Discipline**
- Maintained 400-line limit through strategic code splitting
- Preserved functionality while improving maintainability
- Proper separation of concerns in split files

## Areas for Potential Enhancement

### 1. **Monitoring and Observability**
The summary mentions logging configuration but doesn't detail:
- Metrics collection for 100+ QPS performance monitoring
- Distributed tracing for request flow
- Health checks for the Message Relay service

### 2. **Error Handling Strategy**
While transaction boundaries are mentioned, the summary could benefit from:
- Circuit breaker patterns for Kafka failures
- Dead letter queue handling
- Graceful degradation strategies

### 3. **Security Considerations**
The JWT implementation is mentioned but could include:
- Token rotation strategies
- Rate limiting implementation
- Input validation and sanitization details

## Questions for Clarification

1. **What type of review are you seeking?** 
   - Technical validation of the approach?
   - Assessment of completeness?
   - Feedback on the summary quality?

2. **Are there specific aspects** of the implementation you'd like me to focus on?

3. **Would you like me to examine the actual code** mentioned in the summary, or is this purely a summary review?

The project appears to be well-executed with proper attention to both technical requirements and code quality standards. The systematic approach to addressing code review issues is particularly commendable.

---

