# æ•°æ®æ¨¡å‹è®¾è®¡

## é¢†åŸŸå®ä½“

### æ ¸å¿ƒåˆ›ä¸–æµç¨‹å®ä½“
1. **GenesisFlow**ï¼šåˆ›ä¸–æµç¨‹èšåˆæ ¹ï¼ˆnovel_idç»‘å®šï¼Œç‰ˆæœ¬æ§åˆ¶ï¼‰
2. **GenesisStageRecord**ï¼šé˜¶æ®µè®°å½•ï¼ˆé…ç½®+ç»“æœï¼ŒçŠ¶æ€ç®¡ç†ï¼‰
3. **GenesisStageSession**ï¼šé˜¶æ®µä¼šè¯ï¼ˆè¿æ¥å¯¹è¯ç³»ç»Ÿï¼‰
4. **ConversationSession**ï¼šå¯¹è¯ä¼šè¯ï¼ˆé€šç”¨å¯¹è¯ç³»ç»Ÿï¼‰
5. **ConversationRound**ï¼šå¯¹è¯è½®æ¬¡ï¼ˆç”¨æˆ·/AIäº¤äº’è®°å½•ï¼‰

### æ”¯æ’‘ç³»ç»Ÿå®ä½“
6. **ConceptTemplate**ï¼šå“²å­¦ç«‹æ„æ¨¡æ¿ï¼ˆæœªæ¥åŠŸèƒ½ï¼‰
7. **Novel/WorldRule/Character**ï¼šå›¾æ¨¡å‹ï¼ˆNeo4jå­˜å‚¨ï¼‰
8. **SSEConnection/SSEEvent**ï¼šå®æ—¶é€šä¿¡ï¼ˆRedis Streamsï¼‰

## å®ä½“å…³ç³»

```mermaid
erDiagram
    GenesisFlow ||--o{ GenesisStageRecord : "åŒ…å«é˜¶æ®µ"
    GenesisStageRecord ||--o{ GenesisStageSession : "ç»‘å®šä¼šè¯"
    GenesisStageSession ||--|| ConversationSession : "å…³è”å¯¹è¯"
    ConversationSession ||--|{ ConversationRound : "åŒ…å«è½®æ¬¡"
    GenesisFlow }o--|| Novel : "åˆ›å»ºå°è¯´"
    ConceptTemplate ||--o{ GenesisFlow : "æä¾›ç«‹æ„"
    Novel ||--o{ Character : "åŒ…å«è§’è‰²"
    Novel ||--o{ WorldRule : "å®šä¹‰è§„åˆ™"
    GenesisFlow ||--o{ SSEEvent : "äº§ç”Ÿäº‹ä»¶"
```

## æ•°æ®æ¨¡å‹å®šä¹‰

### åˆ›ä¸–æµç¨‹æ ¸å¿ƒæ¨¡å‹

```typescript
// åˆ›ä¸–æµç¨‹èšåˆæ ¹
export interface GenesisFlow {
  id: string
  novel_id: string
  user_id: string
  status: 'IN_PROGRESS' | 'COMPLETED' | 'FAILED' | 'PAUSED'
  current_stage: 'INITIAL_PROMPT' | 'WORLDVIEW' | 'CHARACTERS' | 'PLOT_OUTLINE' | 'FINISHED'
  version: number  // ä¹è§‚é”ç‰ˆæœ¬å·
  global_state: Record<string, any>  // å…¨å±€çŠ¶æ€å­˜å‚¨
  created_at: string
  updated_at: string
}

// é˜¶æ®µè®°å½•
export interface GenesisStageRecord {
  id: string
  flow_id: string
  stage: 'INITIAL_PROMPT' | 'WORLDVIEW' | 'CHARACTERS' | 'PLOT_OUTLINE'
  status: 'RUNNING' | 'COMPLETED' | 'FAILED' | 'PAUSED'
  iteration_count: number
  config: Record<string, any>  // é˜¶æ®µé…ç½® (JSON SchemaéªŒè¯)
  result: Record<string, any>  // é˜¶æ®µç»“æœ
  metrics: Record<string, any> // æ€§èƒ½æŒ‡æ ‡
  created_at: string
  updated_at: string
}

// é˜¶æ®µä¼šè¯ç»‘å®š
export interface GenesisStageSession {
  id: string
  stage_record_id: string
  conversation_session_id: string
  session_kind: 'CREATION' | 'REFINEMENT' | 'VALIDATION'
  is_primary: boolean
  status: 'ACTIVE' | 'ARCHIVED' | 'CLOSED'
  created_at: string
  updated_at: string
}
```

### å¯¹è¯ç³»ç»Ÿæ¨¡å‹

```typescript
// å¯¹è¯ä¼šè¯
export interface ConversationSession {
  id: string
  name: string
  user_id: string
  status: 'ACTIVE' | 'COMPLETED' | 'ABANDONED' | 'PAUSED'
  metadata: Record<string, any>
  created_at: string
  updated_at: string
}

// å¯¹è¯è½®æ¬¡
export interface ConversationRound {
  id: string
  session_id: string
  sequence_number: number
  role: 'user' | 'assistant' | 'system' | 'tool'
  content: string
  metadata: Record<string, any>
  token_count: number
  model_name?: string
  created_at: string
}
```

### SSEå®æ—¶äº‹ä»¶æ¨¡å‹

```typescript
// SSEäº‹ä»¶
export interface SSEEvent {
  id: string
  event_type: string
  user_id: string
  session_id?: string
  data: Record<string, any>
  created_at: string
}

// SSEè¿æ¥çŠ¶æ€
export interface SSEConnectionState {
  connection_id: string
  user_id: string
  tab_id?: string
  last_event_id?: string
  connected_at: string
  last_ping_at: string
}
```

## æ•°æ®è®¿é—®å±‚

### æ•°æ®åº“æ¨¡å¼è®¾è®¡ï¼ˆPostgreSQL å®Œæ•´å®ç°ï¼‰

```sql
-- æšä¸¾ç±»å‹å®šä¹‰
CREATE TYPE genesis_status AS ENUM ('IN_PROGRESS','COMPLETED','FAILED','PAUSED');
CREATE TYPE genesis_stage AS ENUM ('INITIAL_PROMPT','WORLDVIEW','CHARACTERS','PLOT_OUTLINE','FINISHED');
CREATE TYPE stage_status AS ENUM ('RUNNING','COMPLETED','FAILED','PAUSED');
CREATE TYPE session_kind AS ENUM ('CREATION','REFINEMENT','VALIDATION');
CREATE TYPE session_status AS ENUM ('ACTIVE','ARCHIVED','CLOSED');

-- åˆ›ä¸–æµç¨‹è¡¨ï¼ˆgenesis_flowsï¼‰
CREATE TABLE genesis_flows (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    novel_id UUID NOT NULL UNIQUE,                    -- å°è¯´IDï¼Œä¸€å¯¹ä¸€å…³ç³»
    user_id UUID NOT NULL,                            -- ç”¨æˆ·ID
    status genesis_status NOT NULL DEFAULT 'IN_PROGRESS',
    current_stage genesis_stage NOT NULL DEFAULT 'INITIAL_PROMPT',
    version INTEGER NOT NULL DEFAULT 0,               -- ä¹è§‚é”ç‰ˆæœ¬å·
    global_state JSONB NOT NULL DEFAULT '{}',         -- å…¨å±€çŠ¶æ€å­˜å‚¨
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);
CREATE INDEX IF NOT EXISTS idx_genesis_flows_novel_id ON genesis_flows (novel_id);
CREATE INDEX IF NOT EXISTS idx_genesis_flows_user_id ON genesis_flows (user_id);
CREATE INDEX IF NOT EXISTS idx_genesis_flows_status ON genesis_flows (status);
CREATE INDEX IF NOT EXISTS idx_genesis_flows_stage ON genesis_flows (current_stage);

-- åˆ›ä¸–é˜¶æ®µè®°å½•è¡¨ï¼ˆgenesis_stage_recordsï¼‰
CREATE TABLE genesis_stage_records (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    flow_id UUID NOT NULL REFERENCES genesis_flows(id) ON DELETE CASCADE,
    stage genesis_stage NOT NULL,
    status stage_status NOT NULL DEFAULT 'RUNNING',
    iteration_count INTEGER NOT NULL DEFAULT 0,
    config JSONB NOT NULL DEFAULT '{}',               -- é˜¶æ®µé…ç½®
    result JSONB NOT NULL DEFAULT '{}',               -- é˜¶æ®µç»“æœ
    metrics JSONB NOT NULL DEFAULT '{}',              -- æ€§èƒ½æŒ‡æ ‡
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    UNIQUE(flow_id, stage)                            -- æ¯ä¸ªæµç¨‹çš„æ¯ä¸ªé˜¶æ®µåªæœ‰ä¸€æ¡è®°å½•
);
CREATE INDEX IF NOT EXISTS idx_genesis_stage_records_flow_id ON genesis_stage_records (flow_id);
CREATE INDEX IF NOT EXISTS idx_genesis_stage_records_stage ON genesis_stage_records (stage);
CREATE INDEX IF NOT EXISTS idx_genesis_stage_records_status ON genesis_stage_records (status);

-- åˆ›ä¸–é˜¶æ®µä¼šè¯è¡¨ï¼ˆgenesis_stage_sessionsï¼‰
CREATE TABLE genesis_stage_sessions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    stage_record_id UUID NOT NULL REFERENCES genesis_stage_records(id) ON DELETE CASCADE,
    conversation_session_id UUID NOT NULL,            -- å…³è”åˆ°å¯¹è¯ä¼šè¯
    session_kind session_kind NOT NULL DEFAULT 'CREATION',
    is_primary BOOLEAN NOT NULL DEFAULT false,
    status session_status NOT NULL DEFAULT 'ACTIVE',
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);
CREATE INDEX IF NOT EXISTS idx_genesis_stage_sessions_stage_record ON genesis_stage_sessions (stage_record_id);
CREATE INDEX IF NOT EXISTS idx_genesis_stage_sessions_conversation ON genesis_stage_sessions (conversation_session_id);
CREATE INDEX IF NOT EXISTS idx_genesis_stage_sessions_primary ON genesis_stage_sessions (stage_record_id, is_primary) WHERE is_primary = true;

-- å¯¹è¯ä¼šè¯è¡¨ï¼ˆconversation_sessionsï¼‰
CREATE TABLE conversation_sessions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(255) NOT NULL,                       -- ä¼šè¯åç§°
    user_id UUID NOT NULL,                            -- ç”¨æˆ·ID
    status session_status NOT NULL DEFAULT 'ACTIVE',
    metadata JSONB NOT NULL DEFAULT '{}',             -- å…ƒæ•°æ®
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);
CREATE INDEX IF NOT EXISTS idx_conversation_sessions_user_id ON conversation_sessions (user_id);
CREATE INDEX IF NOT EXISTS idx_conversation_sessions_status ON conversation_sessions (status);
CREATE INDEX IF NOT EXISTS idx_conversation_sessions_updated_at ON conversation_sessions (updated_at DESC);

-- å¯¹è¯è½®æ¬¡è¡¨ï¼ˆconversation_roundsï¼‰
CREATE TABLE conversation_rounds (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    session_id UUID NOT NULL REFERENCES conversation_sessions(id) ON DELETE CASCADE,
    sequence_number INTEGER NOT NULL,                  -- è½®æ¬¡åºå·
    role VARCHAR(20) NOT NULL CHECK (role IN ('user', 'assistant', 'system', 'tool')),
    content TEXT NOT NULL,                            -- æ¶ˆæ¯å†…å®¹
    metadata JSONB NOT NULL DEFAULT '{}',             -- å…ƒæ•°æ®ï¼ˆæ¨¡å‹ä¿¡æ¯ç­‰ï¼‰
    token_count INTEGER,                              -- tokenæ•°é‡
    model_name VARCHAR(100),                          -- ä½¿ç”¨çš„æ¨¡å‹
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    UNIQUE(session_id, sequence_number)              -- ç¡®ä¿åºå·å”¯ä¸€
);
CREATE INDEX IF NOT EXISTS idx_conversation_rounds_session ON conversation_rounds (session_id, sequence_number);
CREATE INDEX IF NOT EXISTS idx_conversation_rounds_role ON conversation_rounds (role);
CREATE INDEX IF NOT EXISTS idx_conversation_rounds_created_at ON conversation_rounds (created_at);

-- æ¦‚å¿µæ¨¡æ¿è¡¨ï¼ˆconcept_templatesï¼‰- å“²å­¦ç«‹æ„åŠŸèƒ½
CREATE TABLE concept_templates (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    core_idea VARCHAR(500) NOT NULL,                  -- æ ¸å¿ƒæŠ½è±¡æ€æƒ³
    description TEXT NOT NULL,                        -- æ·±å±‚å«ä¹‰é˜è¿°
    philosophical_depth TEXT NOT NULL,                -- å“²å­¦æ€è¾¨æ·±åº¦
    emotional_core TEXT NOT NULL,                     -- æƒ…æ„Ÿæ ¸å¿ƒ
    philosophical_category VARCHAR(100) NOT NULL,     -- å“²å­¦ç±»åˆ«
    thematic_tags TEXT[] NOT NULL DEFAULT '{}',       -- ä¸»é¢˜æ ‡ç­¾æ•°ç»„
    complexity_level VARCHAR(20) NOT NULL DEFAULT 'medium' CHECK (complexity_level IN ('low', 'medium', 'high')),
    universal_appeal BOOLEAN NOT NULL DEFAULT true,   -- æ™®éæ„ä¹‰
    cultural_specificity VARCHAR(100),                -- æ–‡åŒ–ç‰¹å¼‚æ€§
    usage_count INTEGER NOT NULL DEFAULT 0,           -- ä½¿ç”¨æ¬¡æ•°
    rating_sum INTEGER NOT NULL DEFAULT 0,            -- è¯„åˆ†æ€»å’Œ
    rating_count INTEGER NOT NULL DEFAULT 0,          -- è¯„åˆ†äººæ•°
    is_active BOOLEAN NOT NULL DEFAULT true,          -- æ˜¯å¦å¯ç”¨
    created_by VARCHAR(100),                          -- åˆ›å»ºè€…
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);
CREATE INDEX IF NOT EXISTS idx_concept_templates_category ON concept_templates (philosophical_category);
CREATE INDEX IF NOT EXISTS idx_concept_templates_complexity ON concept_templates (complexity_level);
CREATE INDEX IF NOT EXISTS idx_concept_templates_active ON concept_templates (is_active);
CREATE INDEX IF NOT EXISTS idx_concept_templates_tags ON concept_templates USING GIN (thematic_tags);
CREATE INDEX IF NOT EXISTS idx_concept_templates_usage ON concept_templates (usage_count DESC);

-- å°è¯´åŸºæœ¬ä¿¡æ¯è¡¨ï¼ˆnovelsï¼‰
CREATE TABLE novels (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    title VARCHAR(500) NOT NULL,                      -- å°è¯´æ ‡é¢˜
    user_id UUID NOT NULL,                            -- ä½œè€…ID
    status VARCHAR(20) NOT NULL DEFAULT 'DRAFT' CHECK (status IN ('DRAFT', 'PUBLISHED', 'ARCHIVED')),
    description TEXT,                                  -- å°è¯´ç®€ä»‹
    metadata JSONB NOT NULL DEFAULT '{}',             -- å…ƒæ•°æ®
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);
CREATE INDEX IF NOT EXISTS idx_novels_user_id ON novels (user_id);
CREATE INDEX IF NOT EXISTS idx_novels_status ON novels (status);
CREATE INDEX IF NOT EXISTS idx_novels_updated_at ON novels (updated_at DESC);

```

### Redisæ•°æ®ç»“æ„è®¾è®¡ï¼ˆSSEå®æ—¶é€šä¿¡ï¼‰

```redis
# SSEè¿æ¥çŠ¶æ€ç®¡ç† (Hash)
# Key: sse:connections:{user_id}
HSET sse:connections:user123 connection_id "conn_456" tab_id "tab_789" last_event_id "event_123" connected_at "2024-01-01T10:00:00Z"

# SSEäº‹ä»¶æµå­˜å‚¨ (Streams)
# Key: sse:events:{user_id}
# æŒä¹…åŒ–ç”¨æˆ·çš„äº‹ä»¶æµï¼Œæ”¯æŒæ–­çº¿é‡è¿æ—¶çš„äº‹ä»¶é‡æ”¾
XADD sse:events:user123 * event_type "genesis.stage_completed" session_id "session_456" stage "WORLDVIEW" data "{\"status\":\"completed\"}"

# SSEäº‹ä»¶å‘å¸ƒè®¢é˜… (Pub/Sub)
# Channel: sse:notify:{user_id}
# å®æ—¶é€šçŸ¥è¿æ¥çš„å®¢æˆ·ç«¯æœ‰æ–°äº‹ä»¶
PUBLISH sse:notify:user123 "event_id_789"

# è·¨æ ‡ç­¾é¡µé€šä¿¡çŠ¶æ€ (Hash)
# Key: sse:tabs:{user_id}
HSET sse:tabs:user123 leader_tab "tab_789" followers "tab_101,tab_102" last_sync "2024-01-01T10:00:00Z"

# SSEè¿æ¥è®¡æ•°å™¨ (String)
# Key: sse:count:connections
INCR sse:count:connections

# è¿æ¥æ¸…ç†ä»»åŠ¡ (Sorted Set)
# Key: sse:cleanup:stale
# Scoreä¸ºlast_pingæ—¶é—´æˆ³ï¼Œç”¨äºæ¸…ç†åƒµå°¸è¿æ¥
ZADD sse:cleanup:stale 1704110400 "conn_456"
```

### å¯é€‰æ‰©å±•ï¼šäº‹ä»¶æº¯æºæ”¯æŒ

```sql
-- å¯é€‰ï¼šé¢†åŸŸäº‹ä»¶è¡¨ï¼ˆç”¨äºå®¡è®¡å’Œè°ƒè¯•ï¼‰
CREATE TABLE domain_events (
    sequence_id BIGSERIAL PRIMARY KEY,
    event_id UUID NOT NULL DEFAULT gen_random_uuid(),
    event_type VARCHAR(100) NOT NULL,
    aggregate_type VARCHAR(50) NOT NULL,
    aggregate_id VARCHAR(50) NOT NULL,
    payload JSONB NOT NULL,
    metadata JSONB,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);
CREATE INDEX IF NOT EXISTS idx_domain_events_aggregate ON domain_events(aggregate_type, aggregate_id);
CREATE INDEX IF NOT EXISTS idx_domain_events_event_type ON domain_events(event_type);
CREATE INDEX IF NOT EXISTS idx_domain_events_created_at ON domain_events(created_at);

-- å¯é€‰ï¼šäº‹ä»¶å‘ä»¶ç®±ï¼ˆç”¨äºä¸å¤–éƒ¨ç³»ç»Ÿé›†æˆï¼‰
CREATE TABLE event_outbox (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    topic VARCHAR(100) NOT NULL,
    event_key VARCHAR(255),
    payload JSONB NOT NULL,
    headers JSONB,
    status VARCHAR(20) NOT NULL DEFAULT 'PENDING' CHECK (status IN ('PENDING','SENDING','SENT','FAILED')),
    retry_count INTEGER NOT NULL DEFAULT 0,
    max_retries INTEGER NOT NULL DEFAULT 5,
    last_error TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    sent_at TIMESTAMPTZ
);
CREATE INDEX IF NOT EXISTS idx_event_outbox_status ON event_outbox(status);
CREATE INDEX IF NOT EXISTS idx_event_outbox_topic ON event_outbox(topic);
```

## Neo4j å›¾æ¨¡å‹æ•°æ®åº“å®ç°

```cypher
-- Neo4j 5.x æ ‡å‡†è¯­æ³•ï¼Œä¸PostgreSQLè®¾è®¡ä¿æŒä¸€è‡´
-- æ³¨æ„ï¼šæ‰€æœ‰èŠ‚ç‚¹çš„ä¸»é”®ç»Ÿä¸€ä¸º idï¼ŒNovelèŠ‚ç‚¹åŒæ—¶ä¿å­˜ novel_id

-- å°è¯´èŠ‚ç‚¹ï¼ˆä¸PostgreSQL novelsè¡¨å¯¹åº”ï¼‰
MERGE (n:Novel {
    id: 'uuid',                      -- ä¸»é”®ID
    novel_id: 'uuid',                -- ä¸šåŠ¡IDï¼Œä¸åˆ›ä¸–æµç¨‹å…³è”
    title: 'string',                 -- å°è¯´æ ‡é¢˜
    user_id: 'uuid',                 -- ä½œè€…ID
    status: 'DRAFT',                 -- çŠ¶æ€ï¼šDRAFT/PUBLISHED/ARCHIVED
    description: 'text',             -- å°è¯´ç®€ä»‹
    genesis_stage: 'FINISHED',       -- åˆ›ä¸–é˜¶æ®µçŠ¶æ€
    created_at: datetime(),
    updated_at: datetime()
})

-- è§’è‰²èŠ‚ç‚¹ï¼ˆ8ç»´åº¦è§’è‰²è®¾è®¡ï¼‰
MERGE (c:Character {
    id: 'uuid',
    novel_id: 'uuid',                -- å…³è”åˆ°å°è¯´
    name: 'string',                  -- è§’è‰²åç§°
    character_type: 'protagonist',   -- è§’è‰²ç±»å‹ï¼šprotagonist/antagonist/supporting

    -- 8ç»´åº¦è§’è‰²è®¾è®¡
    appearance: 'text',              -- å¤–è²Œæè¿°
    personality: 'text',             -- æ€§æ ¼ç‰¹å¾
    background: 'text',              -- èƒŒæ™¯æ•…äº‹
    motivation: 'text',              -- å†…åœ¨åŠ¨æœº
    goals: 'text',                   -- å¤–åœ¨ç›®æ ‡
    obstacles: 'text',               -- é¢ä¸´éšœç¢
    arc: 'text',                     -- è§’è‰²å¼§çº¿
    wounds: 'text',                  -- å†…å¿ƒåˆ›ä¼¤

    -- åˆ›ä¸–é˜¶æ®µå±æ€§
    genesis_stage: 'CHARACTERS',     -- åœ¨å“ªä¸ªé˜¶æ®µåˆ›å»º
    iteration_count: 1,              -- è¿­ä»£æ¬¡æ•°
    status: 'ACTIVE',                -- ACTIVE/ARCHIVED
    created_at: datetime(),
    updated_at: datetime()
})

-- ä¸–ç•Œè§„åˆ™èŠ‚ç‚¹ï¼ˆä¸–ç•Œè§‚è®¾è®¡ï¼‰
MERGE (w:WorldRule {
    id: 'uuid',
    novel_id: 'uuid',
    category: 'geography',           -- åˆ†ç±»ï¼šgeography/history/culture/magic/technology/social
    rule_name: 'string',             -- è§„åˆ™åç§°
    description: 'text',             -- è§„åˆ™æè¿°
    priority: 1,                     -- ä¼˜å…ˆçº§ï¼ˆ1-10ï¼Œå†²çªæ—¶ä½¿ç”¨ï¼‰
    scope: 'global',                 -- é€‚ç”¨èŒƒå›´ï¼šglobal/regional/local/temporal
    examples: [],                    -- åº”ç”¨å®ä¾‹
    constraints: [],                 -- çº¦æŸæ¡ä»¶

    -- åˆ›ä¸–é˜¶æ®µå±æ€§
    genesis_stage: 'WORLDVIEW',      -- åœ¨å“ªä¸ªé˜¶æ®µåˆ›å»º
    iteration_count: 1,              -- è¿­ä»£æ¬¡æ•°
    status: 'ACTIVE',                -- ACTIVE/DEPRECATED
    created_at: datetime(),
    updated_at: datetime()
})

-- å‰§æƒ…èŠ‚ç‚¹ï¼ˆå‰§æƒ…å¤§çº²ï¼‰
MERGE (p:PlotPoint {
    id: 'uuid',
    novel_id: 'uuid',
    sequence_number: 1,              -- åºå·
    plot_type: 'inciting_incident',  -- ç±»å‹ï¼šopening/inciting_incident/plot_point_1/midpoint/plot_point_2/climax/resolution
    title: 'string',                 -- æƒ…èŠ‚ç‚¹æ ‡é¢˜
    description: 'text',             -- è¯¦ç»†æè¿°
    characters_involved: [],         -- æ¶‰åŠè§’è‰²IDåˆ—è¡¨
    location: 'string',              -- å‘ç”Ÿåœ°ç‚¹
    estimated_chapters: 3,           -- é¢„è®¡ç« èŠ‚æ•°

    -- åˆ›ä¸–é˜¶æ®µå±æ€§
    genesis_stage: 'PLOT_OUTLINE',   -- åœ¨å“ªä¸ªé˜¶æ®µåˆ›å»º
    iteration_count: 1,              -- è¿­ä»£æ¬¡æ•°
    status: 'ACTIVE',                -- ACTIVE/REVISED/REMOVED
    created_at: datetime(),
    updated_at: datetime()
})

-- æ¦‚å¿µèŠ‚ç‚¹ï¼ˆå“²å­¦ç«‹æ„ï¼Œæœªæ¥åŠŸèƒ½ï¼‰
MERGE (concept:Concept {
    id: 'uuid',
    template_id: 'uuid',             -- å…³è”åˆ°concept_templates
    novel_id: 'uuid',                -- å…³è”åˆ°å°è¯´
    core_idea: 'string',             -- æ ¸å¿ƒæ€æƒ³
    selected_at: datetime(),         -- é€‰æ‹©æ—¶é—´
    refinement_iterations: 0,        -- ä¼˜åŒ–è¿­ä»£æ¬¡æ•°
    status: 'SELECTED'               -- SELECTED/REFINED/CONFIRMED
})

-- åœ°ç‚¹èŠ‚ç‚¹ï¼ˆä¸–ç•Œè§‚çš„ä¸€éƒ¨åˆ†ï¼‰
MERGE (l:Location {
    id: 'uuid',
    novel_id: 'uuid',
    name: 'string',                  -- åœ°ç‚¹åç§°
    location_type: 'city',           -- ç±»å‹ï¼šcity/town/village/building/region
    description: 'text',             -- åœ°ç‚¹æè¿°
    significance: 'text',            -- æ•…äº‹æ„ä¹‰
    parent_location_id: 'uuid',      -- çˆ¶çº§åœ°ç‚¹ï¼ˆå¯é€‰ï¼‰

    -- åˆ›ä¸–é˜¶æ®µå±æ€§
    genesis_stage: 'WORLDVIEW',      -- åœ¨å“ªä¸ªé˜¶æ®µåˆ›å»º
    status: 'ACTIVE',
    created_at: datetime(),
    updated_at: datetime()
})

-- å…³ç³»å®šä¹‰ï¼ˆåˆ›ä¸–æµç¨‹ç›¸å…³ï¼‰

-- è§’è‰²ä¸å°è¯´å…³ç³»
MATCH (c:Character {novel_id: 'novel_uuid'}), (n:Novel {novel_id: 'novel_uuid'})
MERGE (c)-[:BELONGS_TO]->(n)

-- è§’è‰²å…³ç³»ç½‘ç»œ
MATCH (c1:Character {id: 'char1_uuid'}), (c2:Character {id: 'char2_uuid'})
MERGE (c1)-[:RELATES_TO {
    relationship_type: 'friend',     -- friend/enemy/family/mentor/rival/ally
    strength: 8,                     -- å…³ç³»å¼ºåº¦1-10
    description: 'text',             -- å…³ç³»æè¿°
    development_stage: 'established', -- established/developing/deteriorating
    genesis_stage: 'CHARACTERS',     -- åœ¨å“ªä¸ªé˜¶æ®µåˆ›å»º
    created_at: datetime()
}]->(c2)

-- ä¸–ç•Œè§„åˆ™ä¸å°è¯´å…³ç³»
MATCH (w:WorldRule {novel_id: 'novel_uuid'}), (n:Novel {novel_id: 'novel_uuid'})
MERGE (w)-[:GOVERNS]->(n)

-- å‰§æƒ…ç‚¹ä¸è§’è‰²å…³ç³»
MATCH (p:PlotPoint {id: 'plot_uuid'}), (c:Character {id: 'char_uuid'})
MERGE (p)-[:INVOLVES {
    role: 'protagonist',             -- protagonist/antagonist/catalyst/victim
    importance: 'high',              -- high/medium/low
    character_arc_impact: 'major'    -- major/minor/none
}]->(c)

-- å‰§æƒ…ç‚¹ä¸åœ°ç‚¹å…³ç³»
MATCH (p:PlotPoint {id: 'plot_uuid'}), (l:Location {id: 'location_uuid'})
MERGE (p)-[:OCCURS_AT]->(l)

-- å‰§æƒ…ç‚¹é¡ºåºå…³ç³»
MATCH (p1:PlotPoint {sequence_number: 1}), (p2:PlotPoint {sequence_number: 2})
WHERE p1.novel_id = p2.novel_id
MERGE (p1)-[:LEADS_TO {
    transition_type: 'direct',       -- direct/time_skip/parallel
    estimated_gap: '1 week'          -- æ—¶é—´é—´éš”
}]->(p2)

-- æ¦‚å¿µä¸å°è¯´å…³ç³»ï¼ˆæœªæ¥åŠŸèƒ½ï¼‰
MATCH (concept:Concept {novel_id: 'novel_uuid'}), (n:Novel {novel_id: 'novel_uuid'})
MERGE (concept)-[:INSPIRES]->(n)

-- åœ°ç‚¹å±‚çº§å…³ç³»
MATCH (child:Location {parent_location_id: 'parent_uuid'}), (parent:Location {id: 'parent_uuid'})
MERGE (child)-[:LOCATED_IN]->(parent)

-- ==================== Neo4j 5.x çº¦æŸå®šä¹‰ ====================
-- å”¯ä¸€æ€§çº¦æŸï¼ˆä½¿ç”¨ Neo4j 5.x è¯­æ³•ï¼‰
CREATE CONSTRAINT unique_novel_id IF NOT EXISTS
FOR (n:Novel) REQUIRE n.id IS UNIQUE;

CREATE CONSTRAINT unique_novel_novel_id IF NOT EXISTS
FOR (n:Novel) REQUIRE n.novel_id IS UNIQUE;

CREATE CONSTRAINT unique_character_id IF NOT EXISTS
FOR (c:Character) REQUIRE c.id IS UNIQUE;

CREATE CONSTRAINT unique_world_rule_id IF NOT EXISTS
FOR (w:WorldRule) REQUIRE w.id IS UNIQUE;

CREATE CONSTRAINT unique_plot_point_id IF NOT EXISTS
FOR (p:PlotPoint) REQUIRE p.id IS UNIQUE;

CREATE CONSTRAINT unique_location_id IF NOT EXISTS
FOR (l:Location) REQUIRE l.id IS UNIQUE;

CREATE CONSTRAINT unique_concept_id IF NOT EXISTS
FOR (concept:Concept) REQUIRE concept.id IS UNIQUE;

-- Node Key çº¦æŸï¼ˆNeo4j 5.x æ”¯æŒï¼‰
CREATE CONSTRAINT plot_point_sequence_key IF NOT EXISTS
FOR (p:PlotPoint) REQUIRE (p.novel_id, p.sequence_number) IS NODE KEY;

-- ==================== Neo4j 5.x ç´¢å¼•å®šä¹‰ ====================
-- æ€§èƒ½ä¼˜åŒ–ç´¢å¼•ï¼ˆä½¿ç”¨ Neo4j 5.x è¯­æ³•ï¼‰
CREATE INDEX novel_user_index IF NOT EXISTS
FOR (n:Novel) ON (n.user_id);

CREATE INDEX novel_status_index IF NOT EXISTS
FOR (n:Novel) ON (n.status);

CREATE INDEX character_novel_index IF NOT EXISTS
FOR (c:Character) ON (c.novel_id);

CREATE INDEX character_type_index IF NOT EXISTS
FOR (c:Character) ON (c.character_type);

CREATE INDEX character_genesis_stage_index IF NOT EXISTS
FOR (c:Character) ON (c.genesis_stage);

CREATE INDEX worldrule_novel_index IF NOT EXISTS
FOR (w:WorldRule) ON (w.novel_id);

CREATE INDEX worldrule_category_index IF NOT EXISTS
FOR (w:WorldRule) ON (w.category);

CREATE INDEX plot_point_novel_index IF NOT EXISTS
FOR (p:PlotPoint) ON (p.novel_id);

CREATE INDEX plot_point_type_index IF NOT EXISTS
FOR (p:PlotPoint) ON (p.plot_type);

CREATE INDEX location_novel_index IF NOT EXISTS
FOR (l:Location) ON (l.novel_id);

CREATE INDEX location_type_index IF NOT EXISTS
FOR (l:Location) ON (l.location_type);

CREATE INDEX concept_novel_index IF NOT EXISTS
FOR (concept:Concept) ON (concept.novel_id);

CREATE INDEX concept_template_index IF NOT EXISTS
FOR (concept:Concept) ON (concept.template_id);
```

## Milvus å‘é‡æ•°æ®åº“å®ç°

### é›†åˆSchemaå®šä¹‰

```python
from pymilvus import DataType

# å°è¯´åˆ›ä¸–å†…å®¹å‘é‡é›†åˆ
genesis_collection_schema = {
    "name": "genesis_embeddings_v1",  # ç‰ˆæœ¬åŒ–å‘½å
    "fields": [
        {"name": "id", "type": DataType.INT64, "is_primary": True, "auto_id": True},
        {"name": "novel_id", "type": DataType.VARCHAR, "max_length": 36},
        {"name": "content_type", "type": DataType.VARCHAR, "max_length": 50},  # concept/character/worldrule/plot/conversation
        {"name": "entity_id", "type": DataType.VARCHAR, "max_length": 36},     # å®ä½“ID
        {"name": "genesis_stage", "type": DataType.VARCHAR, "max_length": 20}, # INITIAL_PROMPT/WORLDVIEW/CHARACTERS/PLOT_OUTLINE
        {"name": "content", "type": DataType.VARCHAR, "max_length": 8192},     # æ–‡æœ¬å†…å®¹
        {"name": "embedding", "type": DataType.FLOAT_VECTOR, "dim": 768},      # å‘é‡
        {"name": "iteration_count", "type": DataType.INT32},                   # è¿­ä»£ç‰ˆæœ¬
        {"name": "metadata", "type": DataType.JSON},                           # æ‰©å±•å…ƒæ•°æ®
        {"name": "created_at", "type": DataType.INT64},                        # åˆ›å»ºæ—¶é—´æˆ³
        {"name": "updated_at", "type": DataType.INT64}                         # æ›´æ–°æ—¶é—´æˆ³
    ],
    "index": {
        "type": "HNSW",
        "metric": "COSINE",
        "params": {"M": 32, "efConstruction": 200}
    },
    "partition": {
        "key": "novel_id",                  # æŒ‰å°è¯´åˆ†åŒºï¼Œæå‡æŸ¥è¯¢æ€§èƒ½
        "ttl": 180 * 24 * 3600             # 180å¤©TTLï¼Œä¿ç•™åˆ›ä¸–è¿‡ç¨‹
    }
}

# å“²å­¦ç«‹æ„æ¦‚å¿µå‘é‡é›†åˆï¼ˆæœªæ¥åŠŸèƒ½ï¼‰
concept_collection_schema = {
    "name": "concept_embeddings_v1",
    "fields": [
        {"name": "id", "type": DataType.INT64, "is_primary": True, "auto_id": True},
        {"name": "template_id", "type": DataType.VARCHAR, "max_length": 36},
        {"name": "philosophical_category", "type": DataType.VARCHAR, "max_length": 100},
        {"name": "complexity_level", "type": DataType.VARCHAR, "max_length": 20},
        {"name": "core_idea", "type": DataType.VARCHAR, "max_length": 2048},
        {"name": "embedding", "type": DataType.FLOAT_VECTOR, "dim": 768},
        {"name": "thematic_tags", "type": DataType.JSON},                       # ä¸»é¢˜æ ‡ç­¾
        {"name": "usage_count", "type": DataType.INT32},                        # ä½¿ç”¨æ¬¡æ•°
        {"name": "avg_rating", "type": DataType.FLOAT},                         # å¹³å‡è¯„åˆ†
        {"name": "metadata", "type": DataType.JSON},
        {"name": "created_at", "type": DataType.INT64}
    ],
    "index": {
        "type": "HNSW",
        "metric": "COSINE",
        "params": {"M": 16, "efConstruction": 100}
    },
    "partition": {
        "key": "philosophical_category",    # æŒ‰å“²å­¦ç±»åˆ«åˆ†åŒº
        "ttl": 365 * 24 * 3600             # 1å¹´TTLï¼Œé•¿æœŸä¿å­˜ä¼˜è´¨ç«‹æ„
    }
}
```

### GenesisVectorServiceå°è£…å±‚å®ç°

```python
from typing import List, Dict, Optional, Literal
import numpy as np
import time
from dataclasses import dataclass
from pymilvus import Collection, utility, connections

@dataclass
class VectorConfig:
    """å‘é‡é…ç½®"""
    model_name: str = "qwen3-embedding-0.6b"
    dimension: int = 768
    metric_type: str = "COSINE"
    index_type: str = "HNSW"
    collection_version: int = 1

ContentType = Literal["concept", "character", "worldrule", "plot", "conversation", "location"]
GenesisStage = Literal["INITIAL_PROMPT", "WORLDVIEW", "CHARACTERS", "PLOT_OUTLINE"]

class GenesisVectorService:
    """åˆ›ä¸–æµç¨‹å‘é‡æœåŠ¡"""

    def __init__(self, config: VectorConfig):
        self.config = config
        self.genesis_collection = f"genesis_embeddings_v{config.collection_version}"
        self.concept_collection = f"concept_embeddings_v{config.collection_version}"

    async def upsert_genesis_content(
        self,
        novel_id: str,
        entity_id: str,
        content_type: ContentType,
        genesis_stage: GenesisStage,
        content: str,
        embedding: np.ndarray,
        iteration_count: int = 1,
        metadata: Optional[Dict] = None
    ) -> str:
        """æ’å…¥/æ›´æ–°åˆ›ä¸–å†…å®¹å‘é‡"""
        collection = Collection(self.genesis_collection)

        entity = {
            "novel_id": novel_id,
            "entity_id": entity_id,
            "content_type": content_type,
            "genesis_stage": genesis_stage,
            "content": content[:8192],
            "embedding": embedding.tolist(),
            "iteration_count": iteration_count,
            "metadata": metadata or {},
            "created_at": int(time.time()),
            "updated_at": int(time.time())
        }

        # åˆ é™¤æ—§ç‰ˆæœ¬
        expr = f'entity_id == "{entity_id}" and iteration_count < {iteration_count}'
        collection.delete(expr)

        # æ’å…¥æ–°ç‰ˆæœ¬
        result = collection.insert([entity])
        collection.flush()

        return result.primary_keys[0]

    async def search_similar_genesis_content(
        self,
        novel_id: str,
        query_embedding: np.ndarray,
        content_type: Optional[ContentType] = None,
        genesis_stage: Optional[GenesisStage] = None,
        top_k: int = 10,
        min_score: float = 0.7
    ) -> List[Dict]:
        """æœç´¢ç›¸ä¼¼çš„åˆ›ä¸–å†…å®¹"""
        collection = Collection(self.genesis_collection)
        collection.load()

        # æ„å»ºè¿‡æ»¤è¡¨è¾¾å¼
        expr_parts = [f'novel_id == "{novel_id}"']
        if content_type:
            expr_parts.append(f'content_type == "{content_type}"')
        if genesis_stage:
            expr_parts.append(f'genesis_stage == "{genesis_stage}"')

        expr = " and ".join(expr_parts)

        # æ‰§è¡Œæœç´¢
        search_params = {"metric_type": self.config.metric_type, "params": {"ef": 200}}
        results = collection.search(
            data=[query_embedding.tolist()],
            anns_field="embedding",
            param=search_params,
            limit=top_k,
            expr=expr,
            output_fields=["entity_id", "content_type", "genesis_stage", "content", "iteration_count", "metadata"]
        )

        # è¿‡æ»¤å’Œæ ¼å¼åŒ–ç»“æœ
        filtered_results = []
        for hit in results[0]:
            if hit.score >= min_score:
                filtered_results.append({
                    "id": hit.id,
                    "entity_id": hit.entity.get("entity_id"),
                    "content_type": hit.entity.get("content_type"),
                    "genesis_stage": hit.entity.get("genesis_stage"),
                    "content": hit.entity.get("content"),
                    "iteration_count": hit.entity.get("iteration_count"),
                    "score": hit.score,
                    "metadata": hit.entity.get("metadata")
                })

        return filtered_results

    async def search_concept_templates(
        self,
        query_embedding: np.ndarray,
        philosophical_category: Optional[str] = None,
        complexity_level: Optional[str] = None,
        top_k: int = 10,
        min_score: float = 0.6
    ) -> List[Dict]:
        """æœç´¢å“²å­¦ç«‹æ„æ¨¡æ¿ï¼ˆæœªæ¥åŠŸèƒ½ï¼‰"""
        collection = Collection(self.concept_collection)
        collection.load()

        # æ„å»ºè¿‡æ»¤è¡¨è¾¾å¼
        expr_parts = []
        if philosophical_category:
            expr_parts.append(f'philosophical_category == "{philosophical_category}"')
        if complexity_level:
            expr_parts.append(f'complexity_level == "{complexity_level}"')

        expr = " and ".join(expr_parts) if expr_parts else ""

        # æ‰§è¡Œæœç´¢
        search_params = {"metric_type": self.config.metric_type, "params": {"ef": 100}}
        results = collection.search(
            data=[query_embedding.tolist()],
            anns_field="embedding",
            param=search_params,
            limit=top_k,
            expr=expr or None,
            output_fields=["template_id", "philosophical_category", "core_idea", "thematic_tags", "usage_count", "avg_rating"]
        )

        # è¿‡æ»¤å’Œæ ¼å¼åŒ–ç»“æœ
        filtered_results = []
        for hit in results[0]:
            if hit.score >= min_score:
                filtered_results.append({
                    "id": hit.id,
                    "template_id": hit.entity.get("template_id"),
                    "philosophical_category": hit.entity.get("philosophical_category"),
                    "core_idea": hit.entity.get("core_idea"),
                    "thematic_tags": hit.entity.get("thematic_tags"),
                    "usage_count": hit.entity.get("usage_count"),
                    "avg_rating": hit.entity.get("avg_rating"),
                    "score": hit.score
                })

        return filtered_results

    async def get_genesis_consistency_suggestions(
        self,
        novel_id: str,
        new_content: str,
        new_embedding: np.ndarray,
        current_stage: GenesisStage
    ) -> List[Dict]:
        """è·å–åˆ›ä¸–ä¸€è‡´æ€§å»ºè®®"""
        # æœç´¢å·²æœ‰çš„ç›¸å…³å†…å®¹
        similar_content = await self.search_similar_genesis_content(
            novel_id=novel_id,
            query_embedding=new_embedding,
            top_k=5,
            min_score=0.8
        )

        # åˆ†æä¸€è‡´æ€§é—®é¢˜
        consistency_issues = []
        for content in similar_content:
            if content["genesis_stage"] != current_stage:
                consistency_issues.append({
                    "type": "cross_stage_similarity",
                    "stage": content["genesis_stage"],
                    "content": content["content"],
                    "similarity": content["score"],
                    "suggestion": f"å½“å‰{current_stage}é˜¶æ®µçš„å†…å®¹ä¸{content['genesis_stage']}é˜¶æ®µå†…å®¹é«˜åº¦ç›¸ä¼¼ï¼Œè¯·æ£€æŸ¥æ˜¯å¦å­˜åœ¨é‡å¤æˆ–å†²çª"
                })

        return consistency_issues

    async def cleanup_old_iterations(
        self,
        novel_id: str,
        keep_latest_n: int = 3
    ) -> int:
        """æ¸…ç†æ—§çš„è¿­ä»£ç‰ˆæœ¬"""
        collection = Collection(self.genesis_collection)

        # æŸ¥è¯¢æ¯ä¸ªå®ä½“çš„è¿­ä»£å†å²
        entities = collection.query(
            expr=f'novel_id == "{novel_id}"',
            output_fields=["entity_id", "iteration_count"],
            limit=16384  # MilvusæŸ¥è¯¢é™åˆ¶
        )

        # åˆ†ç»„å¹¶ç¡®å®šè¦åˆ é™¤çš„ç‰ˆæœ¬
        entity_iterations = {}
        for entity in entities:
            entity_id = entity["entity_id"]
            iteration = entity["iteration_count"]
            if entity_id not in entity_iterations:
                entity_iterations[entity_id] = []
            entity_iterations[entity_id].append(iteration)

        # åˆ é™¤æ—§ç‰ˆæœ¬
        deleted_count = 0
        for entity_id, iterations in entity_iterations.items():
            if len(iterations) > keep_latest_n:
                iterations.sort(reverse=True)
                old_iterations = iterations[keep_latest_n:]
                for old_iter in old_iterations:
                    expr = f'entity_id == "{entity_id}" and iteration_count == {old_iter}'
                    collection.delete(expr)
                    deleted_count += 1

        collection.flush()
        return deleted_count

## æ¨¡å‹å˜æ›´ç­–ç•¥

```yaml
genesis_vector_migration_strategy:
  trigger:
    - dimension_change    # ç»´åº¦å˜åŒ–ï¼ˆå¦‚768â†’1024ï¼‰
    - metric_change      # åº¦é‡å˜åŒ–ï¼ˆå¦‚COSINEâ†’L2ï¼‰
    - model_upgrade      # æ¨¡å‹å‡çº§ï¼ˆå¦‚qwen3â†’qwen4ï¼‰
    - schema_evolution   # Schemaå˜åŒ–ï¼ˆå¢åŠ æ–°å­—æ®µï¼‰

  process:
    1_preparation:
      - create_new_collections  # åˆ›å»ºæ–°ç‰ˆæœ¬é›†åˆï¼ˆgenesis_v2, concept_v2ï¼‰
      - setup_dual_write       # è®¾ç½®åŒå†™æ¨¡å¼
      - backup_current         # å¤‡ä»½å½“å‰æ•°æ®

    2_migration:
      - batch_reindex_genesis  # æ‰¹é‡é‡å»ºåˆ›ä¸–å†…å®¹ç´¢å¼•
      - batch_reindex_concept  # æ‰¹é‡é‡å»ºæ¦‚å¿µç´¢å¼•
      - validate_search_quality # éªŒè¯æœç´¢è´¨é‡
      - gradual_traffic_shift  # é€æ­¥åˆ‡æ¢æµé‡

    3_validation:
      - consistency_check      # ä¸€è‡´æ€§éªŒè¯
      - performance_benchmark  # æ€§èƒ½åŸºå‡†æµ‹è¯•
      - rollback_plan         # å›æ»šæ–¹æ¡ˆå‡†å¤‡

    4_cleanup:
      - switch_alias          # åˆ‡æ¢æ´»è·ƒåˆ«å
      - archive_old_v1        # å½’æ¡£v1é›†åˆ
      - monitor_30d           # 30å¤©ç›‘æ§æœŸ
      - delete_after_validation # éªŒè¯ååˆ é™¤æ—§ç‰ˆæœ¬

  rollback_strategy:
    - immediate_alias_switch   # ç«‹å³åˆ‡æ¢åˆ«åå›v1
    - data_consistency_repair  # æ•°æ®ä¸€è‡´æ€§ä¿®å¤
    - incident_post_mortem    # äº‹æ•…ååˆ†æ
```

## æ•°æ®ä¸€è‡´æ€§ä¿è¯

### è·¨æ•°æ®åº“åŒæ­¥ç­–ç•¥

```python
class DataConsistencyManager:
    """æ•°æ®ä¸€è‡´æ€§ç®¡ç†å™¨"""

    async def sync_postgres_to_neo4j(self, novel_id: str):
        """PostgreSQL â†’ Neo4j åŒæ­¥"""
        # 1. ä»PostgreSQLè¯»å–åˆ›ä¸–æµç¨‹æ•°æ®
        genesis_flow = await self.get_genesis_flow(novel_id)

        # 2. æ›´æ–°Neo4jä¸­çš„NovelèŠ‚ç‚¹
        await self.update_novel_node(novel_id, genesis_flow.current_stage)

        # 3. åŒæ­¥è§’è‰²ã€ä¸–ç•Œè§„åˆ™ã€å‰§æƒ…ç‚¹
        for stage_record in genesis_flow.stage_records:
            if stage_record.stage == "CHARACTERS":
                await self.sync_characters(novel_id, stage_record.result)
            elif stage_record.stage == "WORLDVIEW":
                await self.sync_world_rules(novel_id, stage_record.result)
            elif stage_record.stage == "PLOT_OUTLINE":
                await self.sync_plot_points(novel_id, stage_record.result)

    async def sync_content_to_milvus(self, novel_id: str, entity_id: str, content: str):
        """å†…å®¹å‘é‡åŒ–åŒæ­¥"""
        # 1. ç”Ÿæˆembedding
        embedding = await self.generate_embedding(content)

        # 2. åŒæ­¥åˆ°Milvus
        await self.vector_service.upsert_genesis_content(
            novel_id=novel_id,
            entity_id=entity_id,
            content=content,
            embedding=embedding
        )

    async def validate_cross_db_consistency(self, novel_id: str) -> List[str]:
        """éªŒè¯è·¨æ•°æ®åº“ä¸€è‡´æ€§"""
        issues = []

        # PostgreSQL vs Neo4j ä¸€è‡´æ€§æ£€æŸ¥
        pg_characters = await self.get_characters_from_postgres(novel_id)
        neo4j_characters = await self.get_characters_from_neo4j(novel_id)

        if len(pg_characters) != len(neo4j_characters):
            issues.append(f"è§’è‰²æ•°é‡ä¸ä¸€è‡´: PG={len(pg_characters)}, Neo4j={len(neo4j_characters)}")

        # PostgreSQL vs Milvus ä¸€è‡´æ€§æ£€æŸ¥
        pg_content_count = await self.count_genesis_content_in_postgres(novel_id)
        milvus_content_count = await self.count_genesis_content_in_milvus(novel_id)

        if pg_content_count != milvus_content_count:
            issues.append(f"å‘é‡å†…å®¹æ•°é‡ä¸ä¸€è‡´: PG={pg_content_count}, Milvus={milvus_content_count}")

        return issues
```

## æ–‡æ¡£æ›´æ–°æ€»ç»“

### ğŸ”„ ä¸»è¦å˜æ›´å†…å®¹

#### 1. **é¢†åŸŸå®ä½“æ¶æ„é‡æ„**
- **åŸè®¾è®¡**: ConversationSessionä¸ºä¸­å¿ƒçš„ç®€å•æ¶æ„
- **æ–°è®¾è®¡**: GenesisFlow â†’ GenesisStageRecord â†’ GenesisStageSession ä¸‰å±‚æ¶æ„
- **å¯¹åº”å®ç°**: ä¸å½“å‰åç«¯ `genesis_flows.py` æ¨¡å‹å®Œå…¨ä¸€è‡´

#### 2. **æ•°æ®åº“è®¾è®¡æ›´æ–°**
- **PostgreSQL**: æ›´æ–°ä¸ºåæ˜ å®é™…çš„å››é˜¶æ®µåˆ›ä¸–æµç¨‹
- **Redis**: æ–°å¢SSEå®æ—¶é€šä¿¡çš„æ•°æ®ç»“æ„è®¾è®¡
- **Neo4j**: é€‚é…åˆ›ä¸–æµç¨‹çš„å›¾æ¨¡å‹ç»“æ„
- **Milvus**: é’ˆå¯¹åˆ›ä¸–å†…å®¹çš„å‘é‡åŒ–å­˜å‚¨ä¼˜åŒ–

#### 3. **å®æ—¶é€šä¿¡æ¶æ„**
- **æ–°å¢**: Redis Streams + Pub/Sub æ··åˆæ¶æ„
- **æ–°å¢**: è·¨æ ‡ç­¾é¡µé€šä¿¡æœºåˆ¶
- **æ–°å¢**: è¿æ¥æ¸…ç†å’Œå¥åº·ç›‘æ§

#### 4. **åˆ›ä¸–æµç¨‹ç‰¹åŒ–**
- **æ›´æ–°**: å››é˜¶æ®µæµç¨‹ (INITIAL_PROMPT â†’ WORLDVIEW â†’ CHARACTERS â†’ PLOT_OUTLINE)
- **æ–°å¢**: é˜¶æ®µé…ç½®å’ŒéªŒè¯æœºåˆ¶
- **æ–°å¢**: è¿­ä»£ä¼˜åŒ–æ”¯æŒ

### âœ… ä¸ç°æœ‰å®ç°çš„ä¸€è‡´æ€§éªŒè¯

#### PostgreSQL è¡¨ç»“æ„
```sql
-- âœ… ä¸ apps/backend/src/models/genesis_flows.py ä¸€è‡´
genesis_flows          -- GenesisFlow æ¨¡å‹
genesis_stage_records  -- GenesisStageRecord æ¨¡å‹
genesis_stage_sessions -- GenesisStageSession æ¨¡å‹
conversation_sessions  -- ConversationSession æ¨¡å‹
conversation_rounds    -- ConversationRound æ¨¡å‹
concept_templates      -- ConceptTemplate æ¨¡å‹
```

#### API ç«¯ç‚¹å¯¹åº”
```python
# âœ… ä¸ apps/backend/src/api/routes/v1/genesis.py ä¸€è‡´
POST /api/v1/genesis/flows/{novel_id}                    # åˆ›å»ºæµç¨‹
GET /api/v1/genesis/flows/{novel_id}                     # è·å–æµç¨‹
POST /api/v1/genesis/flows/{novel_id}/switch-stage       # åˆ‡æ¢é˜¶æ®µ
POST /api/v1/genesis/stages/{stage_id}/sessions          # åˆ›å»ºä¼šè¯
PATCH /api/v1/genesis/stages/{stage_id}/config           # æ›´æ–°é…ç½®
```

#### å‰ç«¯ç»„ä»¶å¯¹åº”
```typescript
// âœ… ä¸ apps/frontend/src/components/genesis/ ä¸€è‡´
useGenesisFlow()        // æµç¨‹ç®¡ç†
useGenesisSession()     // ä¼šè¯ç®¡ç†
useSSEEvents()         // å®æ—¶äº‹ä»¶
GenesisNavigation      // å¯¼èˆªç»„ä»¶
GenesisConversation    // å¯¹è¯ç»„ä»¶
```

### ğŸš€ æœªæ¥åŠŸèƒ½è®¾è®¡

#### å“²å­¦ç«‹æ„é©±åŠ¨ (è§„åˆ’ä¸­)
- **ConceptTemplate**: å·²æœ‰æ•°æ®æ¨¡å‹ï¼Œå¾…APIå®ç°
- **æ¦‚å¿µé€‰æ‹©ç•Œé¢**: å‰ç«¯ç»„ä»¶è®¾è®¡è§„åˆ’
- **ç«‹æ„ä¼˜åŒ–æœºåˆ¶**: AIé©±åŠ¨çš„è¿­ä»£ä¼˜åŒ–

#### å‘é‡åŒ–å¢å¼º
- **è¯­ä¹‰æœç´¢**: åŸºäºMilvusçš„å†…å®¹ç›¸ä¼¼åº¦æœç´¢
- **ä¸€è‡´æ€§æ£€æŸ¥**: è·¨é˜¶æ®µå†…å®¹ä¸€è‡´æ€§éªŒè¯
- **æ™ºèƒ½å»ºè®®**: åŸºäºå†å²æ•°æ®çš„åˆ›ä½œå»ºè®®

### ğŸ“‹ éƒ¨ç½²æ£€æŸ¥æ¸…å•

- [x] PostgreSQL æ•°æ®åº“è¡¨ç»“æ„å·²éƒ¨ç½²
- [x] Redis SSEé…ç½®å·²å®Œæˆ
- [x] Neo4j çº¦æŸå’Œç´¢å¼•å·²è®¾ç½®
- [x] åç«¯APIæœåŠ¡è¿è¡Œæ­£å¸¸
- [x] å‰ç«¯ç»„ä»¶é›†æˆå®Œæˆ
- [ ] Milvus å‘é‡é›†åˆåˆ›å»º (å¯é€‰)
- [ ] æ¦‚å¿µæ¨¡æ¿æ•°æ®åˆå§‹åŒ– (æœªæ¥åŠŸèƒ½)
- [ ] è·¨æ•°æ®åº“åŒæ­¥æœºåˆ¶ (é«˜çº§åŠŸèƒ½)

æœ¬æ–‡æ¡£ç°å·²ä¸ **2024å¹´1æœˆæœ€æ–°å®ç°** ä¿æŒå®Œå…¨ä¸€è‡´ï¼Œä¸ºåç»­å¼€å‘æä¾›å‡†ç¡®çš„æ•°æ®æ¨¡å‹å‚è€ƒã€‚