# Story 2.3: 实现Prefect的暂停/恢复与回调机制

## Status: Draft

## Revision History
- 2025-07-04: 基于产品和技术双重视角的深度评审反馈进行全面修订
  - 修正Persona定义，避免"系统"反模式
  - 增强AC的具体性和可测性
  - 添加生产级别考虑（Feature Flag、监控、回滚）
  - 完善技术细节和API准确性

## Story

- As a **Workflow Orchestrator**
- I want Prefect工作流能够在需要等待外部事件（如用户反馈）时暂停，并在收到回调后恢复
- so that 我可以实现非阻塞的、事件驱动的复杂业务流程，并高效利用计算资源

**Additional Perspectives:**
- As an **Operations Engineer**, I need resource-efficient workflow suspension to minimize idle compute costs
- As a **Business Process Owner**, I need reliable event-driven flows to ensure user interactions are never lost

## Acceptance Criteria (ACs)

1. **[Given]** 一个Prefect Flow运行到一个需要等待用户输入的`wait_for_user_input`任务。

2. **[When]** 该任务执行时 **[Then]** 它必须在单个数据库事务中：
   - 在`flow_resume_handles`表中创建一条持久化的回调记录，状态为`PENDING_PAUSE`
   - 操作必须是幂等的：相同的correlation_id重复调用应返回已存在的句柄
   - **[And]** 如果DB插入成功但Prefect API调用失败，必须自动回滚DB操作并记录错误

3. **[When]** 向Prefect API请求暂停任务时 **[Then]**：
   - 必须在3次重试（间隔：1s, 2s, 4s）后成功，或标记任务失败
   - 请求必须包含正确的flow_run_id和task_run_id
   - **[And]** API调用失败时，必须清理已创建的flow_resume_handles记录

4. **[When]** Prefect确认任务已暂停 **[Then]** 状态钩子必须在5秒内被触发，将`flow_resume_handles`表中对应记录的状态更新为`PAUSED`，更新操作必须记录在审计日志中（包含timestamp、flow_run_id、correlation_id）。

5. **[Given]** 一个独立的`PrefectCallbackService` **[When]** 它从Kafka消费到包含`correlation_id`的结果事件 **[Then]**：
   - 必须使用Exactly-once语义处理消息（consumer group + manual offset commit）
   - 优先从Redis缓存查询句柄（延迟<10ms），miss时回源DB（延迟<50ms）
   - **[And]** 查询失败时必须发送到死信队列并触发告警

6. **[When]** 调用Prefect API恢复任务时 **[Then]**：
   - 必须将结果数据注入到task的result属性
   - 使用Prefect GraphQL API的`set_task_run_state` mutation
   - **[And]** 恢复操作必须是幂等的：已恢复的任务重复恢复应返回成功但不重复执行

7. **[Given]** 竞态条件（恢复信号比暂停信号先到达） **[Then]**：
   - 系统必须在60秒内通过定期扫描（每5秒）检测到存储的resume_payload
   - 使用Redis分布式锁（Redlock算法，TTL=30s）防止并发恢复
   - **[And]** 最多重试12次后，如仍无法恢复则标记为失败并人工介入

8. **[Given]** 生产环境运行 **[Then]** 系统必须：
   - 通过Feature Flag控制暂停/恢复功能的开关（默认关闭）
   - 暴露Prometheus metrics：handles_created、handles_resumed、resume_failures、resume_latency_seconds
   - **[And]** 支持回滚到非暂停模式运行（通过环境变量PREFECT_PAUSE_ENABLED=false）

## Dev Technical Guidance

### Previous Story Insights
- Story 2.1已批准并实现，六张核心表（包括`flow_resume_handles`）的数据库迁移脚本已创建在 `infrastructure/docker/init/postgres/` 目录下
- `flow_resume_handles`表已包含完整的字段定义、索引、约束和辅助函数
- Story 2.2已批准，定义了基于命令的API和事务性发件箱模式

### Migration Rollback Strategy
**数据库迁移回滚策略**:
```sql
-- 回滚脚本路径：infrastructure/docker/rollback/09-flow-resume-handles-rollback.sql
-- 1. 先备份现有数据
CREATE TABLE flow_resume_handles_backup AS SELECT * FROM flow_resume_handles;

-- 2. 删除依赖的函数和视图
DROP FUNCTION IF EXISTS get_resumable_handle(TEXT) CASCADE;
DROP FUNCTION IF EXISTS mark_handle_resumed(UUID) CASCADE;
DROP FUNCTION IF EXISTS store_resume_payload(TEXT, JSONB) CASCADE;
DROP FUNCTION IF EXISTS cleanup_expired_handles() CASCADE;
DROP FUNCTION IF EXISTS delete_old_resume_handles() CASCADE;
DROP VIEW IF EXISTS flow_resume_handle_statistics CASCADE;

-- 3. 删除表
DROP TABLE IF EXISTS flow_resume_handles CASCADE;

-- 4. 记录回滚操作
INSERT INTO migration_history (version, action, executed_at) 
VALUES ('09-flow-resume-handles', 'ROLLBACK', NOW());
```

### Data Models
**flow_resume_handles表结构** [Source: infrastructure/docker/init/postgres/09-flow-resume-handles.sql]:
- 字段：id, correlation_id, flow_run_id, task_name, resume_handle (JSONB), status (handle_status枚举), resume_payload (JSONB), timeout_seconds, context_data (JSONB), expires_at, resumed_at, created_at, updated_at
- 唯一性约束：`idx_flow_resume_handles_unique_correlation` 确保同一correlation_id在活跃状态（PENDING_PAUSE, PAUSED）下只有一个句柄
- 辅助函数：
  - `get_resumable_handle(correlation_key TEXT)` - 获取可恢复的句柄
  - `mark_handle_resumed(handle_id UUID)` - 标记句柄为已恢复
  - `store_resume_payload(correlation_key TEXT, payload_data JSONB)` - 存储提前到达的恢复数据
  - `cleanup_expired_handles()` - 清理过期句柄
  - `delete_old_resume_handles()` - 删除旧记录

**handle_status枚举值** [Source: infrastructure/docker/init/postgres/02-init-enums.sql]:
- PENDING_PAUSE - 等待暂停确认
- PAUSED - 已暂停，等待恢复
- RESUMED - 已恢复
- EXPIRED - 已过期

### API Specifications
**Prefect相关配置** [Source: architecture/tech-stack.md#L21]:
- Prefect版本：~2.19.0
- 用途：业务流程编排，对数据密集型和动态工作流支持良好
- 包管理器：Python项目使用 `uv` 作为包管理器

**Prefect GraphQL API函数签名**:
```python
# 暂停Flow Run
from prefect import pause_flow_run
from prefect.input import RunInput

class UserInput(RunInput):
    correlation_id: str
    description: str = "等待用户输入"

async def pause_flow_run(
    wait_for_input: Type[RunInput] = UserInput,
    timeout: int = 3600,
    poll_interval: int = 10,
    key: Optional[str] = None
) -> T:
    """暂停工作流直到收到输入"""
    pass

# 恢复Flow Run
from prefect.client import get_client

async def resume_flow_run(
    flow_run_id: str,
    run_input: dict
) -> None:
    """通过GraphQL API恢复暂停的工作流"""
    async with get_client() as client:
        await client.resume_flow_run(
            flow_run_id=flow_run_id,
            run_input=run_input
        )
```

### Component Specifications
**工作流位置**：
- 创建 `apps/backend/src/workflows/` 目录存放所有Prefect工作流
- 基础工作流组件：`apps/backend/src/workflows/base.py`
- 创世工作流：`apps/backend/src/workflows/genesis_flow.py`
- 暂停/恢复任务：`apps/backend/src/workflows/tasks/wait_for_user_input.py`

**服务位置**：
- Prefect回调服务：`apps/backend/src/services/prefect_callback_service.py`
- 服务入口：`apps/backend/src/services/main.py`

**Pydantic模型**：
- 创建 `packages/shared-types/src/models_db.py` 包含数据库表对应的Pydantic模型
- 创建 `packages/shared-types/src/models_prefect.py` 包含Prefect相关的模型

### File Locations
- 工作流目录：`apps/backend/src/workflows/`
- 工作流基类：`apps/backend/src/workflows/base.py`
- 创世工作流：`apps/backend/src/workflows/genesis_flow.py`
- 暂停任务：`apps/backend/src/workflows/tasks/wait_for_user_input.py`
- 回调服务：`apps/backend/src/services/prefect_callback_service.py`
- 服务入口：`apps/backend/src/services/main.py`
- 数据库模型：`packages/shared-types/src/models_db.py`
- Prefect模型：`packages/shared-types/src/models_prefect.py`
- 配置扩展：`apps/backend/src/core/config.py` (添加Prefect配置)

### Testing Requirements
- 使用Pytest进行单元测试 [Source: architecture/test-strategy-and-standards.md#L22]
- 测试覆盖率目标：85% [Source: architecture/test-strategy-and-standards.md#L5]
- 集成测试使用testcontainers [Source: architecture/test-strategy-and-standards.md#L29]

### Technical Constraints
- Python版本：~3.11 [Source: architecture/tech-stack.md#L18]
- 异步编程：优先使用async/await [Source: architecture/coding-standards.md#L28]
- 结构化日志：使用项目定义的结构化日志格式 [Source: architecture/coding-standards.md#L29]
- 错误处理：遵循定义的错误处理策略 [Source: architecture/coding-standards.md#L30]
- 幂等性设计：所有操作必须是幂等的 [Source: architecture/coding-standards.md#L33]
- 分布式锁：使用Redis Redlock算法实现分布式锁，防止并发恢复
- 环境变量：Prefect API配置通过环境变量管理
  - PREFECT_API_URL - Prefect API地址
  - PREFECT_API_KEY - Prefect API密钥（如需要）
  - PREFECT_PAUSE_ENABLED - Feature Flag控制暂停功能（默认false）
  - REDIS_LOCK_TTL - Redis锁TTL（默认30秒）
  - KAFKA_CONSUMER_GROUP - Kafka消费者组ID

## Tasks / Subtasks

- [ ] Task 1: 创建shared-types包和数据库模型 (AC: 2)
  - [ ] 创建 `packages/shared-types` 目录结构
  - [ ] 创建 `packages/shared-types/src/models_db.py` 包含flow_resume_handles表的Pydantic模型
  - [ ] 创建 `packages/shared-types/src/models_prefect.py` 包含Prefect相关数据结构
  - [ ] 创建 `packages/shared-types/pyproject.toml` 配置包依赖

- [ ] Task 2: 实现Prefect工作流基础架构 (AC: 1, 2, 3)
  - [ ] 创建 `apps/backend/src/workflows/` 目录结构
  - [ ] 创建 `apps/backend/src/workflows/base.py` 定义工作流基类
  - [ ] 创建 `apps/backend/src/workflows/tasks/wait_for_user_input.py` 实现暂停任务
  - [ ] 在暂停任务中实现创建flow_resume_handles记录的逻辑
  - [ ] 实现向Prefect API请求暂停的逻辑
  - [ ] 创建 `apps/backend/src/workflows/tasks/__init__.py` 导出任务

- [ ] Task 3: 实现Prefect状态钩子 (AC: 4)
  - [ ] 在 `wait_for_user_input.py` 中实现状态变更钩子
  - [ ] 钩子监听任务状态从PENDING到PAUSED的转换
  - [ ] 更新flow_resume_handles表中记录状态为PAUSED
  - [ ] 添加错误处理和重试逻辑

- [ ] Task 4: 实现PrefectCallbackService服务 (AC: 5, 6)
  - [ ] 创建 `apps/backend/src/services/prefect_callback_service.py`
  - [ ] 实现Kafka事件监听器，监听包含correlation_id的结果事件
  - [ ] 实现从flow_resume_handles表查询恢复句柄的逻辑
  - [ ] 实现Redis缓存层以提高查询性能
  - [ ] 实现调用Prefect API恢复任务的逻辑
  - [ ] 添加结果数据注入功能

- [ ] Task 5: 处理竞态条件 (AC: 7)
  - [ ] 在PrefectCallbackService中实现竞态条件检测
  - [ ] 如果句柄状态为PENDING_PAUSE，使用store_resume_payload函数存储恢复数据
  - [ ] 实现定期检查机制，处理已存储resume_payload的PAUSED句柄
  - [ ] 添加详细的日志记录用于调试竞态条件

- [ ] Task 6: 实现分布式锁机制 (AC: 7)
  - [ ] 在 `apps/backend/src/services/distributed_lock.py` 实现Redis Redlock
  - [ ] 配置Redlock参数：retry_count=3, retry_delay=200ms, TTL=30s
  - [ ] 在PrefectCallbackService中集成分布式锁
  - [ ] 添加锁获取失败的错误处理和重试逻辑
  - [ ] 实现锁的自动续期机制防止长时间操作超时

- [ ] Task 7: 实现Kafka消费者配置 (AC: 5)
  - [ ] 配置Kafka消费者组：`prefect-callback-service-{env}`
  - [ ] 实现Exactly-once语义：enable.idempotence=true, isolation.level=read_committed
  - [ ] 配置手动偏移提交：enable.auto.commit=false
  - [ ] 实现死信队列：`dlq.prefect.callbacks`
  - [ ] 添加消费者健康检查和监控

- [ ] Task 8: 实现监控指标 (AC: 8)
  - [ ] 创建 `apps/backend/src/monitoring/prefect_metrics.py`
  - [ ] 实现Prometheus指标：
    - `prefect_handles_created_total` - 创建的句柄总数
    - `prefect_handles_resumed_total` - 恢复的句柄总数
    - `prefect_resume_failures_total` - 恢复失败总数
    - `prefect_resume_latency_seconds` - 恢复延迟直方图
  - [ ] 在服务中集成指标收集
  - [ ] 暴露 `/metrics` 端点供Prometheus抓取
  - [ ] 添加Grafana仪表板配置

- [ ] Task 9: 创建示例创世工作流 (AC: 1-7)
  - [ ] 创建 `apps/backend/src/workflows/genesis_flow.py`
  - [ ] 实现包含wait_for_user_input任务的示例工作流
  - [ ] 添加工作流部署配置
  - [ ] 创建工作流触发脚本用于测试

- [ ] Task 10: 扩展配置和服务入口 (AC: 5, 6, 8)
  - [ ] 更新 `apps/backend/src/core/config.py` 添加Prefect相关配置
  - [ ] 创建 `apps/backend/src/services/main.py` 作为PrefectCallbackService的入口点
  - [ ] 添加SERVICE_TYPE=prefect-callback的环境变量支持
  - [ ] 实现Feature Flag控制：PREFECT_PAUSE_ENABLED
  - [ ] 实现优雅关闭机制

- [ ] Task 11: 编写单元测试 (AC: 1-8)
  - [ ] 创建 `apps/backend/tests/unit/workflows/test_wait_for_user_input.py`
  - [ ] 创建 `apps/backend/tests/unit/services/test_prefect_callback_service.py`
  - [ ] 测试暂停任务的各种场景
  - [ ] 测试状态钩子的正确触发
  - [ ] 测试竞态条件的处理
  - [ ] 测试分布式锁机制
  - [ ] 测试Feature Flag开关
  - [ ] 模拟Prefect API调用

- [ ] Task 12: 编写集成测试 (AC: 1-8)
  - [ ] 创建 `apps/backend/tests/integration/test_prefect_pause_resume.py`
  - [ ] 使用testcontainers启动PostgreSQL、Redis和Kafka
  - [ ] 测试完整的暂停/恢复流程
  - [ ] 测试竞态条件场景
  - [ ] 验证数据库状态的正确性
  - [ ] 运行覆盖率测试确保达到85%目标

### Deviation Analysis
本故事严格遵循Epic要求，实现了Prefect的暂停/恢复与回调机制。利用已创建的flow_resume_handles表，确保系统的容错性和可靠性。

## Dev Notes

### 关键实现细节

1. **Prefect暂停任务实现**：
   ```python
   from prefect import task, get_run_logger, pause_flow_run
   from prefect.input import RunInput
   from typing import Type
   import asyncio
   from apps.backend.src.core.config import settings
   
   class UserFeedbackInput(RunInput):
       correlation_id: str
       user_response: str
       additional_data: dict = {}
   
   @task
   async def wait_for_user_input(
       correlation_id: str, 
       timeout_seconds: int = 3600
   ) -> UserFeedbackInput:
       logger = get_run_logger()
       
       # Feature Flag检查
       if not settings.PREFECT_PAUSE_ENABLED:
           logger.warning("暂停功能已禁用，跳过等待")
           return UserFeedbackInput(
               correlation_id=correlation_id,
               user_response="SKIPPED",
               additional_data={"reason": "pause_disabled"}
           )
       
       # 1. 创建flow_resume_handles记录（幂等）
       async with get_db_session() as session:
           try:
               handle = await create_resume_handle(
                   session=session,
                   correlation_id=correlation_id,
                   flow_run_id=str(runtime.flow_run.id),
                   task_name="wait_for_user_input",
                   status="PENDING_PAUSE",
                   timeout_seconds=timeout_seconds
               )
               await session.commit()
           except IntegrityError:
               # 幂等处理：句柄已存在
               handle = await get_existing_handle(
                   session, correlation_id
               )
       
       # 2. 暂停工作流
       try:
           user_input = await pause_flow_run(
               wait_for_input=UserFeedbackInput,
               timeout=timeout_seconds,
               key=correlation_id
           )
           
           # 3. 更新句柄状态为PAUSED（通过钩子或直接更新）
           await update_handle_status(handle.id, "PAUSED")
           
           return user_input
           
       except TimeoutError:
           await update_handle_status(handle.id, "EXPIRED")
           raise
   ```

2. **PrefectCallbackService关键逻辑**：
   ```python
   from redlock import Redlock
   from apps.backend.src.monitoring.prefect_metrics import (
       handles_resumed_counter,
       resume_failures_counter,
       resume_latency_histogram
   )
   
   class PrefectCallbackService:
       def __init__(self):
           self.redis = Redis.from_url(settings.REDIS_URL)
           self.redlock = Redlock(
               [self.redis],
               retry_count=3,
               retry_delay=200  # ms
           )
           self.consumer = self._init_kafka_consumer()
       
       def _init_kafka_consumer(self):
           return KafkaConsumer(
               'genesis.callbacks',
               bootstrap_servers=settings.KAFKA_BOOTSTRAP_SERVERS,
               group_id=f'prefect-callback-service-{settings.ENV}',
               enable_auto_commit=False,
               isolation_level='read_committed',
               value_deserializer=lambda m: json.loads(m.decode('utf-8'))
           )
       
       async def handle_resume_event(self, event: dict):
           start_time = time.time()
           correlation_id = event.get("correlation_id")
           result_data = event.get("result")
           
           # 获取分布式锁
           lock_key = f"resume_lock:{correlation_id}"
           with self.redlock.lock(lock_key, ttl=30000):
               try:
                   # 1. 查询恢复句柄（优先Redis缓存）
                   handle = await self._get_handle_with_cache(
                       correlation_id
                   )
                   
                   if not handle:
                       # 竞态条件处理
                       logger.info(f"句柄未就绪，存储payload: {correlation_id}")
                       await store_resume_payload(
                           correlation_id, result_data
                       )
                       return
                   
                   # 2. 恢复Prefect任务
                   async with get_client() as client:
                       await client.resume_flow_run(
                           flow_run_id=handle.flow_run_id,
                           run_input=UserFeedbackInput(
                               correlation_id=correlation_id,
                               user_response=result_data.get("user_response"),
                               additional_data=result_data.get("additional_data", {})
                           ).dict()
                       )
                   
                   # 3. 标记句柄为已恢复
                   await mark_handle_resumed(handle.id)
                   
                   # 记录指标
                   handles_resumed_counter.inc()
                   resume_latency_histogram.observe(
                       time.time() - start_time
                   )
                   
               except Exception as e:
                   logger.error(f"恢复失败: {e}")
                   resume_failures_counter.inc()
                   # 发送到死信队列
                   await self._send_to_dlq(event, str(e))
                   raise
   ```

3. **Feature Flag和生产部署**：
   ```python
   # apps/backend/src/core/config.py
   class Settings(BaseSettings):
       # Prefect配置
       PREFECT_API_URL: str = "http://localhost:4200/api"
       PREFECT_API_KEY: Optional[str] = None
       PREFECT_PAUSE_ENABLED: bool = False  # 默认关闭
       
       # Redis锁配置
       REDIS_LOCK_TTL: int = 30  # 秒
       
       # Kafka配置
       KAFKA_CONSUMER_GROUP: str = f"prefect-callback-{ENV}"
       KAFKA_DLQ_TOPIC: str = "dlq.prefect.callbacks"
   
   # 生产部署检查清单
   # 1. 确保Feature Flag默认关闭
   # 2. 配置监控告警阈值
   # 3. 准备回滚脚本
   # 4. 测试死信队列消费程序
   # 5. 确保Redis主从复制正常
   ```

4. **竞态条件处理**：
   ```python
   async def process_pending_resumes(self):
       """定期处理提前到达的恢复信号"""
       while self.running:
           try:
               # 查询有resume_payload的PAUSED句柄
               async with get_db_session() as session:
                   handles = await session.execute(
                       select(FlowResumeHandle).where(
                           FlowResumeHandle.status == 'PAUSED',
                           FlowResumeHandle.resume_payload.isnot(None),
                           FlowResumeHandle.expires_at > datetime.utcnow()
                       ).limit(10)
                   )
                   
                   for handle in handles.scalars():
                       lock_key = f"resume_lock:{handle.correlation_id}"
                       with self.redlock.lock(lock_key, ttl=30000):
                           await self._resume_with_stored_payload(handle)
               
               await asyncio.sleep(5)  # 每5秒扫描一次
               
           except Exception as e:
               logger.error(f"处理pending resumes失败: {e}")
               await asyncio.sleep(5)
   ```

5. **Redis缓存策略**：
   ```python
   async def _get_handle_with_cache(self, correlation_id: str):
       """优先从Redis获取，缓存未命中时回源DB"""
       cache_key = f"flow_resume_handle:{correlation_id}"
       
       # 1. 尝试从Redis获取
       cached = await self.redis.get(cache_key)
       if cached:
           return FlowResumeHandle.parse_raw(cached)
       
       # 2. 从DB查询
       async with get_db_session() as session:
           result = await session.execute(
               select(FlowResumeHandle).where(
                   FlowResumeHandle.correlation_id == correlation_id,
                   FlowResumeHandle.status.in_(['PAUSED', 'PENDING_PAUSE'])
               )
           )
           handle = result.scalar_one_or_none()
           
           if handle:
               # 3. 写入缓存
               ttl = min(
                   handle.timeout_seconds or 3600,
                   int((handle.expires_at - datetime.utcnow()).total_seconds())
               )
               await self.redis.setex(
                   cache_key,
                   ttl,
                   handle.json()
               )
           
           return handle
   ```

6. **环境变量配置示例**：
   ```bash
   # Prefect配置
   PREFECT_API_URL=http://localhost:4200/api
   PREFECT_API_KEY=your-api-key
   PREFECT_PAUSE_ENABLED=false  # 生产默认关闭
   
   # Redis配置
   REDIS_URL=redis://devRedis123!@192.168.2.201:6379
   REDIS_LOCK_TTL=30
   
   # Kafka配置
   KAFKA_BOOTSTRAP_SERVERS=192.168.2.201:9092
   KAFKA_CONSUMER_GROUP=prefect-callback-prod
   KAFKA_DLQ_TOPIC=dlq.prefect.callbacks
   
   # 监控配置
   PROMETHEUS_PORT=9090
   ```

### Testing

Dev Note: Story Requires the following tests:

- [ ] Pytest Unit Tests: (nextToFile: false), coverage requirement: 85%
  - 位置：`apps/backend/tests/unit/workflows/test_wait_for_user_input.py`
  - 位置：`apps/backend/tests/unit/services/test_prefect_callback_service.py`
  - 位置：`apps/backend/tests/unit/workflows/test_base.py`

- [ ] Pytest Integration Test: location: `apps/backend/tests/integration/`
  - `test_prefect_pause_resume.py` - 完整的暂停/恢复流程测试
  - `test_race_condition_handling.py` - 竞态条件场景测试
  - 使用testcontainers启动所需的外部服务
  - 运行覆盖率：`pytest apps/backend/tests/ --cov=apps/backend/src --cov-report=html --cov-report=term-missing`

Manual Test Steps:
1. 启动本地Prefect服务器：`prefect server start`
2. 启动PrefectCallbackService：`cd apps/backend && SERVICE_TYPE=prefect-callback uv run python src/services/main.py`
3. 部署示例工作流：`cd apps/backend && uv run python -m workflows.deploy`
4. 触发工作流：`cd apps/backend && uv run python -m workflows.trigger_genesis`
5. 观察工作流在Prefect UI中暂停
6. 通过Kafka发送恢复事件：
   ```json
   {
     "correlation_id": "task-uuid",
     "result": {
       "user_feedback": "继续执行",
       "additional_data": {}
     }
   }
   ```
7. 验证工作流恢复并完成

## Dev Agent Record

### Agent Model Used: {{Agent Model Name/Version}}

### Debug Log References

[[LLM: (Dev Agent) If the debug is logged to during the current story progress, create a table with the debug log and the specific task section in the debug log - do not repeat all the details in the story]]

### Completion Notes List

[[LLM: (Dev Agent) Anything the SM needs to know that deviated from the story that might impact drafting the next story.]]

### File List

[[LLM: (Dev Agent) List every new file created, or existing file modified in a bullet list.]]

### Change Log

[[LLM: (Dev Agent) Track document versions and changes during development that deviate from story dev start]]

| Date | Version | Description | Author |
| :--- | :------ | :---------- | :----- |

## QA Results

[[LLM: QA Agent Results]]