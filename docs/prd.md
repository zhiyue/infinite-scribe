# 多智能体网络小说自动写作系统(InfiniteScribe) 产品需求文档 (PRD)

## 目标和背景上下文

### 目标

*   实现一部超过100万字小说的全流程自动化生成，人工干预率低于10%。
*   验证生成内容的成本效益，使其相比传统人工创作降低至少70%。
*   探索与内容平台或工作室的商业合作模式。
*   将人类的角色从“创作者”转变为“监督者”，极大地提升长篇小说的生产效率。
*   系统性地解决长篇创作中的一致性、扩展性和效率三大难题。

### 背景上下文

当前，长篇网络小说的创作是一个劳动密集型产业，面临着创作速度跟不上读者需求、作者灵感枯竭、以及维持长期故事一致性等巨大挑战。现有工具无法满足自动化、规模化生产的需求，导致内容生产存在根本瓶颈。本项目旨在通过一个由多个专业AI智能体协作的自动化系统，来应对这些挑战，将小说创作带入工业化生产的新时代。

### Change Log

| Date | Version | Description | Author |
| :--- | :------ | :---------- | :----- |
|      | 1.0     | Initial Draft | John (PM) |
|      | 1.1     | Added API requirements, Finalized Epics & Stories | John (PM) |
|      | 1.2     | Revised UI flow, project dashboard, and project-scoped knowledge base concepts. | John (PM) |
|      | 1.3     | Clarified global navigation structure. | John (PM) |
|      | 1.4     | **架构对齐更新**: 根据最终架构决策，更新了功能性需求以包含Neo4j多数据库策略、版本控制和工作流追踪。 | John (PM) |


## 需求

### 功能性需求 (Functional Requirements)

*   **FR1: (创世流程)** 系统必须提供一个由“世界铸造师Agent”主导的、与人类监督者进行对话式交互的创世流程。该流程在项目开始前确定小说的核心设定（主题、世界观、核心角色、初始剧情），并在PostgreSQL中创建记录后，**为该小说在Neo4j中创建一个独立的、物理隔离的图数据库**。
*   **FR2: (工作流编排)** 系统必须使用Prefect实现一个可根据任务结果进行分支的动态工作流，至少能处理标准路径、修订路径和一致性修正路径。
*   **FR3: (事件驱动)** 所有智能体服务之间必须通过事件总线（Kafka）进行异步通信，以实现服务解耦。
*   **FR4: (剧情策划)** “剧情策划师Agent”必须能够周期性或按需分析故事全局，并发布高层次的剧情指令（如引入新反派、开启新支线）。
*   **FR5: (大纲规划)** “大纲规划师Agent”必须能够接收高层剧情指令，并将其转化为具体的章节情节大纲。
*   **FR6: (场景设计)** “导演Agent”必须能够将章节大纲分解为带有节奏和视角设定的场景序列。
*   **FR7: (角色管理)** “角色专家Agent”必须能够按需创建新的角色卡，并规划已有角色在具体场景中的对话与互动。
*   **FR8: (世界观构建)** “世界观构建师Agent”必须能够根据创作需要，扩展或更新世界观设定，并将其持久化。
*   **FR9: (章节写作)** “作家Agent”必须能够综合导演和角色专家的指令，调用大模型API生成最终的章节草稿。
*   **FR10: (质量评审)** “评论家Agent”必须能够对章节草稿的文学质量、节奏和趣味性进行评估，并输出结构化的评分和评语。
*   **FR11: (一致性校验)** “事实核查员Agent”必须能够将章节草稿的内容与**该小说专属的知识库（PG属性和Neo4j图谱）**中已确立的世界观、角色设定进行比对，并报告不一致之处。
*   **FR12: (Web UI)** 系统必须提供一个Web UI，其核心功能包括：
    *   一个“项目仪表盘/书籍列表”作为应用入口，展示所有已创建的书籍及其状态，并提供“创建新书籍”的入口。若无书籍，则引导用户创建。
    *   从项目仪表盘进入“项目详情页”，该页面包含针对特定书籍的左侧导航（如章节列表、知识库、监控、设置等），并提供触发章节生成、实时监控工作流状态、查看已生成章节内容的功能。
    *   在项目详情页的显著位置（如右上角）提供返回“项目仪表盘”或切换其他书籍的机制。
    *   支持用户启动“创世流程”以设定新书籍。
*   **FR13: (数据持久化)** 系统必须将所有生成的核心产物（章节、大纲、角色卡、世界观条目）和元数据持久化存储在PostgreSQL数据库和Minio对象存储中。
*   **FR14: (记忆与检索)** 系统必须能够将内容的关键信息（如章节摘要、角色简介）生成向量嵌入并存储在Milvus中。智能体在为特定书籍工作时，其上下文检索**必须限定**在该书籍关联的知识库范围内（包括PG表、Neo4j图数据库和Milvus集合），以确保检索到的信息高度相关且无数据串扰。
*   **FR15: (控制API)** 系统必须提供一个基于FastAPI的、安全的RESTful“控制API”，作为前端UI与后端工作流系统的交互入口。
*   **FR16: (API指令功能)** 控制API必须提供以下指令性端点(Endpoints)：
    *   一个用于启动“创世流程”的端点。
    *   一个用于启动指定小说“章节生成流程”的端点。
*   **FR17: (API查询功能)** 控制API必须提供以下查询性端点：
    *   一个用于根据任务ID查询工作流当前状态的端点。
    *   一个用于获取已生成章节列表及内容的端点。
    *   一个用于获取所有书籍项目列表及其概况的端点。
*   **FR18: (版本控制)** 系统必须为核心创作产物（特别是章节）提供版本控制。每次由AI（如`RewriterAgent`）进行的修改都应生成一个新版本，并记录修改原因和操作者，旧版本应可追溯。
*   **FR19: (工作流追踪)** 系统必须将工作流的运行实例、任务状态以及Agent的关键活动持久化到数据库中，以便进行详细的审计、调试和性能分析。

### 非功能性需求 (Non-Functional Requirements)

*   **NFR1:** 所有智能体之间的内部通信**必须**通过事件总线（Kafka）进行，以确保服务的松耦合和可扩展性。
*   **NFR2:** 所有对大语言模型的API调用**必须**通过LiteLLM代理服务，以实现统一的成本控制、日志记录和模型切换。
*   **NFR3:** 后端服务**必须**使用Python语言，并基于FastAPI和Pydantic进行开发，以保证类型安全和高性能。
*   **NFR4:** 前端监控界面**必须**使用React、TypeScript、Vite和Shadcn UI等指定的技术栈构建。
*   **NFR5:** 系统**必须**能够追踪并报告每万字的平均API调用成本，并能归因到具体的Agent活动，以确保其维持在预算范围内。
*   **NFR6:** 所有核心服务（智能体、API等）**必须**被容器化（例如使用Docker），以实现环境一致性和部署便捷性。
*   **NFR7:** 系统**必须**为所有关键操作（如事件发布、任务完成、API调用失败）提供结构化的日志，以便于调试和监控。
*   **NFR8:** 控制API必须提供自动生成的、符合OpenAPI 3.0规范的交互式API文档（例如通过Swagger UI或Redoc）。
*   **NFR9:** 所有对控制API的访问必须经过身份验证和授权，确保只有合法的用户才能触发和查询任务。
*   **NFR10: (数据隔离)** 每个小说项目的知识图谱数据**必须**在数据库层面进行物理隔离（例如，在Neo4j中使用独立的数据库），以防止数据串扰和性能干扰。

## 用户界面设计目标

### 整体UX愿景

我们的UI/UX愿景是 **“清晰、可控、高效”**。界面应作为一个功能强大的驾驶舱，让监督者能够轻松启动复杂的创作流程，直观地监控其状态，并快速审查结果。设计应优先考虑信息密度和功能性，而非装饰性美学，采用简洁、以数据为中心的设计语言。

### 关键交互范式

*   **异步任务管理:** 核心交互是触发一个长时间运行的后台任务（小说创作）。UI必须能立即提供任务已启动的反馈，然后通过轮询或WebSocket（待定）实时更新其状态，用户无需停留在页面上等待。
*   **向导式创世流程:** “创世”过程将设计成一个分步骤的向导（Wizard），引导用户完成主题、世界观和角色的设定，每一步都有清晰的指引和反馈。
*   **日志流与可视化:** 工作流的监控将以实时日志流的形式呈现，关键事件（如“章节已评分”、“发现不一致”）会高亮显示，并可能伴有简单的流程图可视化。

### 全局导航结构

应用的主导航（例如，始终可见的侧边栏或顶部栏）应保持简洁，专注于全局功能。其核心链接应主要包括：

*   **项目仪表盘 (Dashboard):** 用户管理和访问所有书籍项目的入口。
*   **全局监控中心 (Global Monitoring Center):** (如果其功能与单个项目的监控视图显著不同) 用于查看系统级的整体健康状况、性能指标和成本分析。
*   **用户设置 (User Settings):** 用于管理用户账户信息、偏好设置等。

### 核心屏幕和视图

从产品角度看，MVP阶段最关键的视图包括：

*   **1. 项目仪表盘/书籍列表 (Dashboard / Book List):**
    *   作为应用的**主要入口点**，对应全局导航中的“项目仪表盘”。
    *   显示所有用户已创建的小说项目列表，以卡片或列表形式展示。
    *   每个项目都应展示其总体进度（如已生成章节数/目标章节数）、当前状态（如“创世中”、“生成中”、“已暂停”、“已完成”）。
    *   提供一个显眼的“创建新小说”按钮或引导，如果列表为空，则更突出显示创建引导。
    *   此页面**不包含**特定于某个书籍项目的左侧导航栏。
*   **2. 创世向导 (Creation Wizard):**
    *   一个多步骤的表单/界面，从“项目仪表盘”发起，用于引导用户完成“创世阶段”的设定。
*   **3. 项目详情页 (Project Detail View):**
    *   从“项目仪表盘”点击某个具体书籍项目后进入。
    *   **包含针对当前书籍的左侧导航栏**，导航项可能包括：章节列表、知识库（当前书籍的设定、角色等）、工作流监控、项目设置等。
    *   在页面**右上角或顶部显著位置提供返回“项目仪表盘”的链接或一个“切换书籍”的下拉菜单**。
    *   展示特定小说工作流的实时状态图（基于Prefect状态）。
    *   显示一个滚动的事件日志（来自Kafka的关键事件）。
    *   列出所有已生成的章节，并提供点击查看详情的入口。
*   **4. 章节阅读器 (Chapter Viewer):**
    *   一个简洁的文本显示界面，用于阅读和审查生成的章节内容，从“项目详情页”的章节列表进入。
*   **5. 知识库浏览器 (Knowledge Base Viewer - Project Scoped):**
    *   作为“项目详情页”内的一个导航项或标签页。
    *   **内容严格限定于当前选定书籍**的世界观条目、角色卡片等。
    *   提供搜索和筛选功能，帮助用户快速定位当前书籍的特定设定。

### 可访问性 (Accessibility)

*   **标准:** 我们将以 **WCAG 2.1 AA** 级别作为目标。
*   **说明:** 这是一个行业公认的良好标准，确保了界面对大多数用户（包括有视觉或运动障碍的用户）都是可用和可理解的。

### 品牌 (Branding)

*   **假设:** 由于这是一个内部或专家使用的工具，我们将采用一个极简的、功能驱动的品牌风格。
*   **建议:** 使用一个干净的、以深色模式为主的“开发者工具”主题。这有助于长时间使用时减轻眼部疲劳，并能更好地突出状态颜色（如成功、失败、警告）。

### 目标设备和平台

*   **平台:** **Web端，采用响应式设计，但优先为桌面端优化。**
*   **说明:** 监督和监控这类复杂系统的工作通常在桌面或笔记本电脑上进行。界面应在移动设备上可用（例如，可以快速查看状态），但所有复杂操作（如创世流程）都将为大屏幕设计。

## 技术假设

这些技术假设是基于项目简报中明确的技术栈选择，并为架构师提供了在设计系统时必须遵守的约束和指导。

### 仓库结构

*   **Monorepo (单一代码库)**
    *   **理由:** 项目包含多个紧密协作的服务（前端、多个Agent服务）和共享的代码（如类型定义、通用工具函数）。Monorepo 结构能够极大地简化依赖管理、代码复用和跨服务重构，是此类项目的最佳实践。

### 服务架构

*   **微服务架构 (Sidecar 模式)**
    *   **理由:** 每个AI智能体都将作为一个独立的微服务运行。这种架构提供了极高的flexibility和可扩展性，允许我们独立地开发、部署和扩展每个智能体的能力，而不会影响到其他部分。Sidecar模式确保了核心业务逻辑与通用功能（如日志、监控）的分离。
    *   **数据访问**: Agent服务必须具备动态连接到不同数据库的能力，以支持“一小说一库”的数据隔离策略。

### 测试要求

*   **单元测试优先:** 每个服务和组件都必须有全面的单元测试覆盖。
*   **集成测试:** 必须为服务间的关键交互路径（特别是通过Kafka的事件流）编写集成测试。
*   **端到端(E2E)测试:** 至少需要一个E2E测试来验证从UI触发到章节最终生成的完整流程。
*   **测试便利性:** 后端服务应提供必要的脚本或工具，以便在本地环境中轻松运行测试。

### 额外技术假设和要求

*   **类型安全:** 整个项目（前端和后端）必须强制实行严格的类型安全。共享的类型定义应放在Monorepo的共享包中，以确保前端、后端和事件生产者/消费者之间的数据契约一致。
*   **配置管理:** 服务的配置（如API密钥、数据库连接字符串、功能开关）必须与代码分离。配置应通过环境变量或专门的配置服务来加载。
*   **容器化:** 所有后端服务（Agents, API等）都必须被设计为在Docker容器中运行，并提供相应的Dockerfile。
*   **异步处理:** 鉴于系统的事件驱动特性，所有长时间运行的任务（如调用LLM API、处理复杂逻辑）都必须以异步、非阻塞的方式实现，以避免服务进程被夯住。

## 史诗

### 史诗列表 (最终版)

*   **Epic 1: 基础设施与核心服务引导 (Infrastructure & Core Services Bootstrap)**
    *   **目标:** 搭建并配置项目运行所需的核心技术骨架，包括事件总线、API网关、数据库和容器化环境，并部署一个能响应健康检查的空服务。
*   **Epic 2: “创世阶段”人机交互流程 (Genesis Flow Implementation)**
    *   **目标:** 实现“世界铸造师Agent”与前端UI的交互流程，让用户能够完成一部小说的初始设定，并为该小说创建独立的、持久化的数据存储（包括独立的图数据库）。
*   **Epic 3: 端到端章节生成MVP (End-to-End Chapter Generation MVP)**
    *   **目标:** 实现一个最简化的、单路径的章节自动生成与审查流程，让所有核心执行与审查智能体能够在**隔离的小说环境**中串联工作，并产出第一章内容。
*   **Epic 4: 规模化生成与稳定性验证 (Scale & Stability Validation)**
    *   **目标:** 在MVP流程的基础上，实现系统的自动化、无人值守的连续章节生成能力，并完成首个10万字（约30-35章）的生成目标，以验证系统的稳定性和长文本一致性。
*   **Epic 5: 全功能长篇小说生成 (Full-Scale Novel Generation)**
    *   **目标:** 集成并启用所有高级功能（如图数据库的深度应用、高级智能体、动态工作流、人机反馈闭环），完成一部至少100万字的、高质量、高一致性的长篇小说生成，达到商业化交付标准。

## Epic 1: 基础设施与核心服务引导 (Infrastructure & Core Services Bootstrap)

**目标:** 搭建并配置项目运行所需的核心技术骨架，包括事件总线、API网关、数据库和容器化环境，并部署一个能响应健康检查的空服务。

### Story 1.1: 初始化Monorepo项目结构

*   **As a** 开发团队,
*   **I want** 一个配置好的、基于pnpm workspaces的Monorepo项目结构,
*   **so that** 我可以统一管理前端、后端和共享代码，并确保代码风格和规范的一致性。
*   **Acceptance Criteria:**
    1.  项目根目录包含 `pnpm-workspace.yaml` 文件。
    2.  创建 `apps` 目录用于存放独立应用（如 `frontend`, `backend`）。
    3.  创建 `packages` 目录用于存放共享代码（如 `eslint-config`, `typescript-config`, `shared-types`）。
    4.  根目录的 `package.json` 配置好工作区。
    5.  ESLint 和 Prettier 的共享配置已创建并应用到整个工作区。
    6.  共享的 `tsconfig.json` 文件已创建，为所有TypeScript项目提供基础配置。

### Story 1.2: 部署核心事件与存储服务

*   **As a** 系统,
*   **I want** Kafka, PostgreSQL, Milvus, Neo4j, 和 Minio 服务能够通过Docker Compose在本地一键启动,
*   **so that** 所有后端服务都有一个稳定、可用的事件总线和数据存储环境。
*   **Acceptance Criteria:**
    1.  项目根目录下有一个 `docker-compose.yml` 文件。
    2.  运行 `docker-compose up -d` 可以成功启动Kafka, Zookeeper, PostgreSQL, Milvus, Neo4j, 和 Minio 容器。
    3.  所有服务的端口都已正确映射到本地，并记录在文档中。
    4.  PostgreSQL 和 Neo4j 数据库的初始用户和密码已通过环境变量配置。
    5.  Minio 服务的访问密钥和私钥已通过环境变量配置，并自动创建一个名为 `novels` 的bucket。

### Story 1.3: 创建并部署健康的API网关服务

*   **As a** 开发团队,
*   **I want** 一个基于FastAPI的、容器化的API网关服务，它能连接到数据库并提供一个健康的检查端点,
*   **so that** 我可以验证后端服务的基础配置和部署流程是通畅的。
*   **Acceptance Criteria:**
    1.  在 `apps/backend/src/api` 目录下创建API Gateway的FastAPI应用。
    2.  该应用能够成功读取环境变量并连接到Docker中运行的PostgreSQL和Neo4j数据库。
    3.  提供一个 `/health` 的GET端点，当数据库连接正常时，该端点返回 `{"status": "ok"}` 和 `200` 状态码。
    4.  使用统一的 `apps/backend/Dockerfile`，通过 `SERVICE_TYPE=api-gateway` 环境变量运行API Gateway。
    5.  更新 `docker-compose.yml`，使其可以构建并启动 `api-gateway` 服务（使用统一的backend镜像）。
    6.  启动后，可以通过 `http://localhost:8000/health` 成功访问到健康检查接口。

### Story 1.4: 创建并部署基础的前端仪表盘UI

*   **As a** 开发团队,
*   **I want** 一个基于React和Vite的、容器化的基础前端应用，它能调用API网关的健康检查接口，并显示一个项目列表或创建引导,
*   **so that** 我可以验证前后端分离的开发和部署流程，并为用户提供正确的应用入口。
*   **Acceptance Criteria:**
    1.  在 `apps/frontend` 目录下创建一个新的React (TypeScript + Vite)应用。
    2.  应用**默认页面为“项目仪表盘/书籍列表”**。
    3.  页面加载时，会调用后端 `api-gateway` 服务的 `/health` 接口，并显示系统健康状态。
    4.  如果用户没有任何书籍项目，页面应显示一个“创建新书籍”的引导或按钮。
    5.  如果用户已有书籍项目（此阶段可模拟数据），则以卡片或列表形式展示。
    6.  为该服务编写一个 `Dockerfile`。
    7.  更新 `docker-compose.yml`，使其可以构建并启动 `frontend` 服务。
    8.  启动后，可以通过浏览器访问前端页面并正确显示内容。

## Epic 2: “创世阶段”人机交互流程 (Genesis Flow Implementation)

**目标:** 实现“世界铸造师Agent”与前端UI的交互流程，让用户能够完成一部小说的初始设定，并为该小说创建独立的、持久化的数据存储（包括独立的图数据库）。

### Story 2.1: 设计并实现创世数据模型

*   **As a** 系统,
*   **I want** 在PostgreSQL中创建用于存储小说核心设定属性的数据表，在Neo4j中定义核心节点标签和关系类型，并通过Pydantic/TypeScript定义好对应的数据模型,
*   **so that** 我有一个结构化的、类型安全的方式来持久化、校验和关联用户在创世阶段输入的所有信息。
*   **Acceptance Criteria:**
    1.  在PostgreSQL中创建 `novels`, `worldview_entries`, `characters`, `story_arcs` 等核心属性表，以及 `chapter_versions`, `agent_activities` 等支持性表。
    2.  在Monorepo的 `packages/shared-types` 中，使用Pydantic为PostgreSQL表创建Python数据模型，并为前端创建对应的TypeScript接口。
    3.  API网关服务能够导入这些模型，用于API请求和响应的校验。
    4.  API网关服务能够连接到Neo4j实例，并具备执行数据库管理命令（如 `CREATE DATABASE`）的权限。

### Story 2.2: 实现创世流程的控制API端点

*   **As a** 前端开发者,
*   **I want** 一组API端点来驱动和管理创世流程,
*   **so that** 我可以在UI上构建一个分步骤的向导来与后端交互。
*   **Acceptance Criteria:**
    1.  在API网关中创建一个新的路由模块，用于处理 `/genesis` 相关的请求。
    2.  提供一个 `POST /genesis/start` 端点，用于创建一个新的、处于“创世中”状态的小说条目（在PG中），并**触发一个异步任务为该小说创建独立的Neo4j数据库**。该端点返回一个唯一的 `genesis_session_id`。
    3.  提供 `POST /genesis/{session_id}/worldview`, `POST /genesis/{session_id}/characters`, `POST /genesis/{session_id}/plot` 端点，用于提交各阶段设定。这些端点会负责将数据属性存入PG，并将节点和关系存入**该小说专属的Neo4j数据库**。
    4.  提供一个 `POST /genesis/{session_id}/finish` 端点，用于结束创世流程，并将小说状态更新为“待生成”。
    5.  所有端点都必须使用Pydantic模型对请求体进行严格校验。

### Story 2.3: 开发“世界铸造师Agent”的核心逻辑

*   **As a** 系统,
*   **I want** 一个“世界铸造师Agent”服务，它能够根据简单的指令生成结构化的创世内容建议,
*   **so that** 我可以辅助用户完成世界观和角色的设定，而不是让用户从零开始。
*   **Acceptance Criteria:**
    1.  在 `apps/backend/src/agents/worldsmith` 目录下创建世界铸造师Agent服务。
    2.  该服务能够接收一个包含主题和简短描述的请求。
    3.  服务调用大模型API，生成一份包含多个世界观条目和多个核心角色概念的JSON草案。
    4.  该服务提供一个内部调用的接口（或通过事件总线），供API网关在创世流程中调用。
    5.  使用统一的 `apps/backend/Dockerfile`，通过 `SERVICE_TYPE=agent-worldsmith` 环境变量运行该服务，并集成到 `docker-compose.yml` 中。

### Story 2.4: 构建前端“创世向导”UI

*   **As a** 监督者,
*   **I want** 一个分步骤的、引导式的UI界面来完成新小说的创世过程,
*   **so that** 我可以轻松地输入我的核心创意，并与AI协作完成初始设定。
*   **Acceptance Criteria:**
    1.  在前端应用中，从**“项目仪表盘”的“创建新小说”按钮**发起，创建一个新的路由 `/create-novel`，导向创世向导。
    2.  向导至少包含以下步骤：1. 主题与立意 -> 2. 世界观设定 -> 3. 核心角色 -> 4. 初始剧情。
    3.  在第2步和第3步，UI可以调用“世界铸造师Agent”（通过API网关）来获取AI生成的建议，并允许用户在此基础上进行修改、删除或添加。
    4.  用户在每一步填写的信息都会通过调用相应的API端点被保存到PG和**该小说专属的Neo4j数据库**。
    5.  完成所有步骤后，用户可以点击“完成创世”按钮，系统将跳转回项目仪表盘，并能看到刚刚创建的新小说项目。

## Epic 3: 端到端章节生成MVP (End-to-End Chapter Generation MVP)`

**目标:** 实现一个最简化的、单路径的章节自动生成与审查流程，让所有核心执行与审查智能体能够在**隔离的小说环境**中串联工作，并产出第一章内容。

### Story 3.1: 部署所有核心Agent服务

*   **As a** 系统,
*   **I want** 所有核心的执行与审查Agent（大纲规划师、导演、角色专家、作家、评论家、事实核查员、世界观构建师、剧情策划师）都作为独立的、容器化的服务被部署,
*   **so that** 它们可以订阅和发布事件，构成完整的章节生成流水线。
*   **Acceptance Criteria:**
    1.  为每个核心Agent在 `apps/backend/src/agents/` 目录下创建对应的模块。
    2.  每个服务都是一个基础的Python应用，能够**动态地连接到指定小说的Neo4j数据库**，以及连接到Kafka, PostgreSQL, Minio。
    3.  所有Agent使用统一的 `apps/backend/Dockerfile`，通过 `SERVICE_TYPE` 环境变量选择运行的服务。
    4.  `docker-compose.yml` 文件被更新，以包含并能一键启动所有这些Agent服务（使用统一的backend镜像，不同的SERVICE_TYPE）。
    5.  每个Agent启动后，都会向Kafka的特定topic（如 `agent.health.events`）发布一条“I am alive”的消息。

### Story 3.2: 实现事件Schema注册与验证

*   **As a** 系统,
*   **I want** 一个集中的、基于Pydantic的事件Schema注册表,
*   **so that** 所有发布到Kafka的事件都经过严格的格式和类型验证，确保数据契约的一致性。
*   **Acceptance Criteria:**
    1.  在Monorepo的 `packages/shared-types` 中，创建一个 `events.py` 文件。
    2.  为章节生成流程中的每一个关键事件（如 `ChapterWriting.Requested`, `Outline.Created`, `SceneDesign.Completed`, `Character.Created`, `CharacterInteraction.Designed`, `WorldviewEntry.Created`, `Chapter.Drafted`, `Critique.Completed`, `FactCheck.Completed` 等）创建一个对应的Pydantic模型。
    3.  每个Agent在发布事件前，必须使用相应的Pydantic模型来序列化其数据。
    4.  每个Agent在消费事件时，必须使用相应的Pydantic模型来反序列化和验证接收到的数据。

### Story 3.3: 实现单路径章节生成工作流 (Prefect)

*   **As a** 监督者,
*   **I want** 在UI上点击“生成下一章”按钮后，系统能够通过Prefect自动地、按顺序地触发所有核心Agent来完成一章的创作,
*   **so that** 我可以验证端到端的自动化流程是通畅的。
*   **Acceptance Criteria:**
    1.  API网关提供一个 `POST /novels/{novel_id}/generate-chapter` 的端点。
    2.  调用此端点后，Prefect会启动一个章节生成工作流，**所有任务都携带 `novel_id` 上下文**。
    3.  工作流按顺序发布事件，依次激活大纲规划师、导演、角色专家、世界观构建师（如果需要）、和作家Agent。
    4.  每个Agent完成工作后，都会将其产出（如大纲、场景卡）存入Minio，在PostgreSQL中记录元数据，在**该小说专属的Neo4j数据库**中更新关系，然后发布一个“完成”事件。
    5.  后一个Agent能够根据前一个Agent的“完成”事件，获取其产出并继续工作。
    6.  最终，“作家Agent”成功生成章节草稿，并发布 `Chapter.Drafted` 事件。

### Story 3.4: 实现单路径评审与结果展示

*   **As a** 监督者,
*   **I want** 在章节草稿生成后，评审Agent能够自动进行分析，并将最终的章节和评审结果展示在UI上,
*   **so that** 我可以看到完整的“创作-审查”闭环的结果。
*   **Acceptance Criteria:**
    1.  “评论家Agent”和“事实核查员Agent”订阅 `Chapter.Drafted` 事件。
    2.  它们在接收到事件后，**在其专属的小说知识库上下文**中执行评审逻辑（事实核查员会查询该小说专属的Neo4j和PG），并发布 `Critique.Completed` （包含评分、评论）。
    3.  API网关提供一个 `GET /chapters/{chapter_id}` 的端点，可以获取章节内容及其所有的评审结果。
    4.  前端的**项目详情页**能够轮询或通过WebSocket接收更新，当章节状态变为“已评审”时，可以查看到章节内容和来自两个评审Agent的意见。

## Epic 4: 规模化生成与稳定性验证 (Scale & Stability Validation)

**目标:** 在MVP流程的基础上，实现系统的自动化、无人值守的连续章节生成能力，并完成首个10万字（约30-35章）的生成目标，以验证系统的稳定性和长文本一致性。

### Story 4.1: 实现自动化连续生成调度器

*   **As a** 系统,
*   **I want** 一个基于Prefect的调度器，它能在上一章成功完成后，自动触发下一章的生成流程,
*   **so that** 我可以实现无人值守的、连续的小说创作。
*   **Acceptance Criteria:**
    1.  创建一个新的Prefect Flow，作为主调度器。
    2.  该Flow可以被手动启动，并设定一个目标章节数（例如，生成30章）。
    3.  Flow会循环调用在Epic 3中创建的“单章节生成工作流”。
    4.  每当一个章节工作流成功完成（状态为“已发布”），主调度器会自动为下一章启动新的工作流。
    5.  如果任何一个章节工作流失败，主调度器会暂停，并记录下失败的章节和原因。
    6.  UI上需要有一个地方可以启动这个“连续生成”任务，并能看到整体的进度（例如，“正在生成第 5 / 30 章”）。

### Story 4.2: 实现动态工作流分支（修订与修正）

*   **As a** 系统,
*   **I want** 章节生成工作流能够根据评审结果动态地选择不同的执行路径,
*   **so that** 系统可以自动处理质量不佳或内容不一致的草稿，形成一个真正的纠错闭环。
*   **Acceptance Criteria:**
    1.  在Prefect的单章节工作流中，增加条件判断逻辑（Conditional Tasks）。
    2.  当“评论家Agent”的评分低于预设阈值（如7.0分）时，工作流必须自动触发一个“修订任务”，并将草稿和评论发送给一个“改写者Agent”。
    3.  当“事实核查员Agent”报告了内容不一致时，工作流必须自动触发一个“一致性修正任务”，并将草稿和不一致报告发送给“改写者Agent”。
    4.  “改写者Agent”完成修改后，会生成一个新的章节版本，并将修改后的草稿重新送回评审流程。
    5.  UI的监控视图需要能清晰地展示出当前章节正在经历“修订”或“修正”的状态。

### Story 4.3: 增强知识库的上下文检索能力

*   **As a** AI智能体,
*   **I want** 在开始工作前，能够从**当前小说专属的知识库**中检索到与任务最相关的上下文信息,
*   **so that** 我可以做出更符合长期设定的决策，并保持故事的一致性。
*   **Acceptance Criteria:**
    1.  创建一个共享的“知识库服务”或在 `shared-types` 包中提供一个工具库。
    2.  该服务提供一个 `retrieve_context(novel_id, task_description)` 函数，输入为当前小说的ID和任务描述。
    3.  该函数**严格限定在 `novel_id` 关联的数据范围内**进行操作：
        a. 从PostgreSQL中获取该小说的最新世界观和角色卡属性。
        b. **连接到该小说专属的Neo4j数据库**，查询与该小说当前章节/角色相关的关键关系和历史事件。
        c. 从Milvus中对任务描述进行向量相似度搜索，找出该小说最相关的3-5个历史章节的摘要。
    4.  所有核心执行Agent（大纲规划师、导演、角色专家、作家）在执行任务前，都必须调用此函数来获取上下文。
    5.  检索到的上下文将被注入到它们发送给大模型的Prompt中。

### Story 4.4: 实现基础的成本与性能监控

*   **As a** 监督者,
*   **I want** 在UI上看到一个基础的监控仪表盘，展示规模化生成过程中的关键指标,
*   **so that** 我可以评估系统的成本效益和运行稳定性。
*   **Acceptance Criteria:**
    1.  LiteLLM代理服务需要配置为将每次API调用的成本和耗时数据记录到PostgreSQL的 `agent_activities` 表中。
    2.  API网关提供一个新的端点 `GET /metrics`。
    3.  该端点能聚合计算并返回以下指标：已生成的总字数、平均每万字API成本、平均章节生成时间、章节修订率。
    4.  前端应用中创建一个新的“监控”页面（可能是全局的，也可能是项目详情页内的一个标签），以图表或数字的形式展示这些指标。

## Epic 5: 全功能长篇小说生成 (Full-Scale Novel Generation)

**目标:** 集成并启用所有高级功能（如图数据库的深度应用、高级智能体、动态工作流增强、人机反馈闭环），完成一部至少100万字的、高质量、高一致性的长篇小说生成，达到商业化交付标准。

### Story 5.1: Neo4j图数据库的深度应用与查询优化

*   **As a** 系统,
*   **I want** 充分利用Neo4j图数据库进行复杂的逻辑推理和关系查询,
*   **so that** 我可以为“事实核查员”和“剧情策划师”提供更深层次的一致性保证和剧情洞察。
*   **Acceptance Criteria:**
    1.  为Neo4j中的核心关系类型和节点属性创建复合索引以优化查询性能。
    2.  “事实核查员Agent”的逻辑被重构，以执行更复杂的Cypher查询来验证多跳关系和时间序列逻辑（例如，“A角色在事件X发生时，不可能在Y地点，因为他当时正与Z角色在Q地点互动”）。
    3.  “剧情策划师Agent”在进行战略评估时，会查询Neo4j以分析当前的角色关系网密度、关键情节节点的连接度等图特有的指标。
    4.  UI上提供一个更高级的知识图谱浏览器，允许用户在**隔离的数据库环境**中执行自定义的Cypher查询或通过预设模板探索图数据。

### Story 5.2: 开发并集成高级“叙事型”智能体

*   **As a** 剧情策划师,
*   **I want** 引入更专业的“叙事型”智能体来提升故事的复杂性和趣味性,
*   **so that** 生成的小说不再是平铺直叙，而是充满悬念和吸引力。
*   **Acceptance Criteria:**
    1.  开发并部署一个新的“**伏笔设计Agent (ForeshadowingAgent)**”。它会根据“剧情策划师”的长期指令，在当前章节中巧妙地植入一些看似无意、实则关键的细节或对话，并将其作为元数据记录在Neo4j中（例如，一个 `:PLANTED_FORESHADOW` 关系连接到章节节点）。
    2.  开发并部署一个新的“**情节反转Agent (PlotTwistAgent)**”。在关键的剧情节点，它会被激活，用于设计出人意料但又合乎逻辑的情节反转，并确保反转与Neo4j中已有的伏笔或角色动机相符。
    3.  Prefect工作流被更新，以包含调用这些高级智能体的可选阶段，这些阶段的触发可能由“剧情策划师”的指令或特定的故事里程碑决定。

### Story 5.3: 实现完整的人机反馈与精修闭环

*   **As a** 监督者,
*   **I want** 一个专门的UI界面来对已生成的章节进行精细化修改和批注，并将我的修改作为高质量数据反馈给系统,
*   **so that** 我可以对AI的创作进行最终的“润色”，并帮助系统学习我的偏好。
*   **Acceptance Criteria:**
    1.  在前端UI的章节阅读器中，增加一个“编辑模式”。
    2.  在编辑模式下，用户可以像在Word文档中一样，直接修改文本、添加批注。
    3.  当用户保存修改后，系统会创建一个新的 `chapter_versions` 记录，并将 `change_reason` 标记为“人工修改”，同时将原始版本和用户修改版一同存储。
    4.  API网关提供一个端点，用于接收这些“精修数据”。
    5.  （后MVP）这些高质量的对比数据将被用于未来对自研模型或微调模型的训练的准备工作。
    6.  工作流中增加一个“人工审核”状态，允许在发布前等待人类的最终批准。如果人工审核驳回，可以附带修改意见，触发“改写者Agent”进行定向修改。

### Story 5.4: 实现全面的可观测性与告警 (Langfuse集成)

*   **As a** 开发团队,
*   **I want** 将所有Agent的详细思考链、工具使用和API调用过程都集成到Langfuse中,
*   **so that** 我可以深入地调试任何一个Agent的行为，并对系统进行端到端的性能和质量追踪。
*   **Acceptance Criteria:**
    1.  在 `docker-compose.yml` 中添加并配置Langfuse服务。
    2.  所有Agent的核心逻辑都被Langfuse的SDK包裹，以追踪其执行过程（包括Prompt、LLM响应、Token使用情况）。
    3.  LiteLLM被配置为将其所有的请求/响应日志转发到Langfuse。
    4.  可以从Langfuse的UI中，清晰地看到从一个事件触发到最终章节生成的完整调用链和每个步骤的详细信息。
    5.  基于Langfuse收集的关键指标（如API调用失败率、内容生成一致性错误率、平均Token消耗）设置告警规则，并通过邮件或Slack通知开发团队。